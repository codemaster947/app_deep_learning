{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSIM-PITWYFa"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/app_deep_learning/blob/main/t81_558_class_13_4_tpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDTXd8-Lmp8Q"
   },
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "**Module 13: Advanced/Other Topics**\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncNrAEpzmp8S"
   },
   "source": [
    "# Module 13 Video Material\n",
    "\n",
    "* Part 13.1: Using Denoising AutoEncoders [[Video]](https://www.youtube.com/watch?v=BBrRD89sTk8&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_13_1_auto_encode.ipynb)\n",
    "* Part 13.2: Anomaly Detection [[Video]](https://www.youtube.com/watch?v=wubZ516TkI8&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_13_2_anomaly.ipynb)\n",
    "* Part 13.3: Model Drift and Retraining [[Video]](https://www.youtube.com/watch?v=F4395B1ySpg&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_13_3_retrain.ipynb)\n",
    "* **Part 13.4: Tensor Processing Units (TPUs)** [[Video]](https://www.youtube.com/watch?v=Cp3xOyxOZNo&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_13_4_tpu.ipynb)\n",
    "* Part 13.5: Future Directions in Artificial Intelligence [[Video]](https://www.youtube.com/watch?v=RjxvEZh73Yc&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_13_5_new_tech.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lux_6KOXMU94"
   },
   "source": [
    "# Google CoLab Instructions\n",
    "\n",
    "The following code ensures that Google CoLab is running the correct version of TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fU9UhAxTmp8S",
    "outputId": "5caa882a-b8c4-4b37-be65-9e349778fe9a"
   },
   "outputs": [],
   "source": [
    "# Detect Colab if present\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q09yMGGcmp9N"
   },
   "source": [
    "# Part 13.4: Tensor Processing Units (TPUs)\n",
    "\n",
    "This book focuses primarily on NVIDIA Graphics Processing Units (GPUs) for deep learning acceleration. NVIDIA GPUs are not the only option for deep learning acceleration. TensorFlow continues to gain additional support for AMD and Intel GPUs. TPUs are also available from Google cloud platforms to accelerate deep learning. The focus of this book and course is on NVIDIA GPUs because of their wide availability on both local and cloud systems.\n",
    "\n",
    "Though this book focuses on NVIDIA GPUs, we will briefly examine Google Tensor Processing Units (TPUs). These devices are an AI accelerator Application-Specific Integrated Circuit (ASIC) developed by Google. They were designed specifically for neural network machine learning, mainly using Google's TensorFlow software. Google began using TPUs internally in 2015 and in 2018 made them available for third-party use, both as part of its cloud infrastructure and by offering a smaller version of the chip for sale.\n",
    "\n",
    "The full use of a TPU is a complex topic that I only introduced in this part. Supporting TPUs is slightly more complicated than GPUs because specialized coding is needed. Changes are rarely required to adapt CPU code to GPU for most relatively simple mainstream GPU tasks in PyTorch. I will cover the mild code changes needed to utilize in this part. You might also want to refer to the [CoLab PyTorch TPU guide](https://colab.research.google.com/github/pytorch/xla/blob/master/contrib/colab/getting-started.ipynb#scrollTo=OApBOAe1fpH_) provided by Google.\n",
    "\n",
    "We will begin by checking the environment to see if a TPU is present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PEtB2fpRSov-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gftO2Vj6v6Du"
   },
   "source": [
    "If a TPU is not detected follow the instructions and select a TPU hardware accelerator. Next, we will install the necessary software into CoLab to allow TPU access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AOvubSN0SyWj",
    "outputId": "42cedbe3-8be1-4593-d7a5-62e833d46f54"
   },
   "outputs": [],
   "source": [
    "!pip install cloud-tpu-client==0.10 torch==2.0.0 torchvision==0.15.1 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VOe-ijQrX6Q"
   },
   "source": [
    "Please note, once the above code runs in CoLab, it will request you to restart the environment before continuing. Please follow these instructions, you likely are provided with a \"RESTART RUNTIME\" button.\n",
    "\n",
    "Next, we will query to see if we have TPUs available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w3vfKjYhQkhs",
    "outputId": "1304f5fa-cfe6-4afa-afb9-ba36d548a42c"
   },
   "outputs": [],
   "source": [
    "import torch_xla.core.xla_model as xm\n",
    "tpu_cores = xm.get_xla_supported_devices()\n",
    "print(\"TPU Cores Available:\", tpu_cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_hjljzjwGz7"
   },
   "source": [
    "It is typical in Google CoLab to have 8 TPUs; this is roughly analogous to multiple GPUs, and, unfortunately, requires some of the same coordination in code. I will use just a single TPU core, which is plug-and-play compatible with most of the software in this book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6KCY2f6NVFj8",
    "outputId": "ba1f86b9-3fda-43d1-d00f-ff945b698ad8"
   },
   "outputs": [],
   "source": [
    "# Creates a random tensor on xla:1 (a Cloud TPU core)\n",
    "device = xm.xla_device()\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pcsi1kRvxiGz"
   },
   "source": [
    "Now that the device is set, we can use the TPU core just like we would a GPU or Apple MPS. Overall, I've found CUDA to be the most compatible/capable, followed by TPS, and lastly MPS. Though, I MPS is adding features all the time. We will begin by looking at the simple Neural Network example [provied by PyTorch](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7VgLHNlUU7M5",
    "outputId": "72df8f62-6150-4fc6-d47e-9c2250987083"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Simple example network from\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "# Places network on the default TPU core\n",
    "net = Net().to(device)\n",
    "\n",
    "# Creates random input on the default TPU core\n",
    "input = torch.randn(1, 1, 32, 32, device=device)\n",
    "\n",
    "# Runs network\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0x20nlRGyh6E"
   },
   "source": [
    "This code defines and utilizes a simple convolutional neural network (CNN) using PyTorch, a popular machine learning library in Python. The CNN, named Net, is a subclass of torch.nn.Module, which is the base class for all neural network modules in PyTorch.\n",
    "\n",
    "Key components and operations of the Net class are:\n",
    "\n",
    "1. Initialization (__init__): This method initializes two convolutional layers (conv1 and conv2) and three fully connected (linear) layers (fc1, fc2, and fc3). The convolutional layers are used for extracting features from the input image, and the linear layers are used for classification tasks.\n",
    "\n",
    "2. Forward Propagation (forward): This method defines the forward pass of the network. It applies a sequence of operations on the input tensor x:\n",
    "\n",
    "3. Convolution followed by ReLU activation and max pooling is performed twice, first with conv1 and then with conv2.\n",
    "The output is then flattened (transformed from a multi-dimensional tensor into a 1D tensor).\n",
    "T\n",
    "his flattened tensor is passed through three linear layers with ReLU activation functions (except for the last linear layer).\n",
    "Flattening (num_flat_features): This method calculates the total number of features in a flattened tensor, which is needed to determine the input size for the first linear layer.\n",
    "\n",
    "After defining the Net class, the code creates an instance of this network and moves it to a specific device (dev), which could be a CPU, GPU, or TPU, depending on how dev is defined. It then creates a random input tensor mimicking an image of size 32x32 with 1 channel (e.g., grayscale) and runs this input through the network (net(input)). The output of the network is then printed, which typically represents the class scores for a classification task.\n",
    "\n",
    "This code is a classic example of defining and using a CNN in PyTorch for tasks like image classification.\n",
    "\n",
    "## Mandelbrot Set\n",
    "\n",
    "Earlier in this book, I provided code to calculate the Mandelbrot set on either CPU or CUDA. Currently, the Mac MPS does not support complex numbers and, as a result, cannot run the Mandelbrot Set example. Here, I present the same code from Module 3, with no changes. Setting the device is sufficient to run this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEPLRe7Cu4JI"
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import torch\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "# Take a NumPy array and render it as a Mandelbrot.\n",
    "def render(a):\n",
    "    a_cyclic = (a * 0.3).reshape(list(a.shape) + [1])\n",
    "    img = np.concatenate(\n",
    "        [\n",
    "            10 + 20 * np.cos(a_cyclic),\n",
    "            30 + 50 * np.sin(a_cyclic),\n",
    "            155 - 80 * np.cos(a_cyclic),\n",
    "        ],\n",
    "        2,\n",
    "    )\n",
    "    img[a == a.max()] = 0\n",
    "    a = img\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = BytesIO()\n",
    "    return PIL.Image.fromarray(a)\n",
    "\n",
    "\n",
    "# Loop through the render cycles for. Mandlebrot plot.\n",
    "def mandelbrot_helper(grid_c, current_values, counts, cycles):\n",
    "    for i in range(cycles):\n",
    "        # The Mandlebrot formula\n",
    "        temp = current_values * current_values + grid_c\n",
    "        not_diverged = torch.abs(temp) < 4\n",
    "        current_values.copy_(temp)\n",
    "        counts.copy_(torch.add(counts, not_diverged.double()))\n",
    "\n",
    "\n",
    "# Render a Mandelbrot plot at the specified location, zoom, and render cycles.\n",
    "def mandelbrot(render_size, center, zoom, cycles):\n",
    "    f = zoom / render_size[0]\n",
    "\n",
    "    real_start = center[1] - (render_size[1] / 2) * f\n",
    "    real_end = real_start + render_size[1] * f\n",
    "    imag_start = center[0] - (render_size[0] / 2) * f\n",
    "    imag_end = imag_start + render_size[0] * f\n",
    "\n",
    "    real_range = torch.arange(\n",
    "        real_start, real_end, f, dtype=torch.float32, device=device\n",
    "    )\n",
    "    imag_range = torch.arange(\n",
    "        imag_start, imag_end, f, dtype=torch.float32, device=device\n",
    "    )\n",
    "    real, imag = torch.meshgrid(real_range, imag_range, indexing=\"ij\")\n",
    "    grid_c = torch.complex(imag, real)\n",
    "    current_values = torch.clone(grid_c)\n",
    "    counts = torch.Tensor(torch.zeros_like(grid_c, dtype=torch.float32))\n",
    "\n",
    "    mandelbrot_helper(grid_c, current_values, counts, cycles)\n",
    "    return counts.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPeFj7h604fb"
   },
   "source": [
    "With the support functions defined, we can now run the Mandelbrot Set example on the TPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "3OAONSiGvHYV",
    "outputId": "306574b7-73fe-4ec4-e9b7-7e580f4a0454"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Pytorch does not currently support complex numbers on MPS\n",
    "temp_device = device\n",
    "if device == \"mps\":\n",
    "    device = \"cpu\"\n",
    "\n",
    "counts = mandelbrot(\n",
    "    # render_size=(1920,1080), # HD\n",
    "    render_size=(640, 480),\n",
    "    center=(-0.5, 0),\n",
    "    zoom=4,\n",
    "    cycles=200,\n",
    ")\n",
    "\n",
    "img = render(counts)\n",
    "print(img.size)\n",
    "\n",
    "# restore device\n",
    "device = temp_device\n",
    "\n",
    "# display image\n",
    "img"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
