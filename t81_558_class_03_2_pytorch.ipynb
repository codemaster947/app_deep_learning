{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLEEW13uCtiJ"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/app_deep_learning/blob/main/t81_558_class_03_2_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5oX6K_-JCtiL"
   },
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "\n",
    "**Module 3: Introduction to PyTorch**\n",
    "\n",
    "- Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "- For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzlMdsudCtiL"
   },
   "source": [
    "# Module 3 Material\n",
    "\n",
    "- Part 3.1: Deep Learning and Neural Network Introduction [[Video]](https://www.youtube.com/watch?v=d-rU5IuFqLs&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_03_1_neural_net.ipynb)\n",
    "- **Part 3.2: Introduction to PyTorch** [[Video]](https://www.youtube.com/watch?v=Pf-rrhMolm0&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_03_2_pytorch.ipynb)\n",
    "- Part 3.3: Encoding a Feature Vector for PyTorch Deep Learning [[Video]](https://www.youtube.com/watch?v=7SGPm2tIT58&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_03_3_feature_encode.ipynb)\n",
    "- Part 3.4: Early Stopping and Network Persistence [[Video]](https://www.youtube.com/watch?v=lS0vvIWiahU&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_03_4_early_stop.ipynb)\n",
    "- Part 3.5: Sequences vs Classes in PyTorch [[Video]](https://www.youtube.com/watch?v=NOu8jMZx3LY&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_03_5_pytorch_class_sequence.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpVJpj2DCtiM"
   },
   "source": [
    "# Google CoLab Instructions\n",
    "\n",
    "The following code ensures that Google CoLab is running and maps Google Drive if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wU1AMzx8CtiM",
    "outputId": "014519db-db87-41b6-f5b6-e0a68e2fdffe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Zg-zNx0CtiN"
   },
   "source": [
    "# Part 3.2: Introduction to PyTorch\n",
    "\n",
    "PyTorch[[Cite:paszke2019pytorch]](https://arxiv.org/abs/1912.01703) is an open-source software library for machine learning in various kinds of perceptual and language understanding tasks. It is currently used for research and production by different teams at [Meta Platforms](https://about.facebook.com/). Companies have built several pieces of deep learning software on top of PyTorch, including Tesla Autopilot, Uber's Pyro, Hugging Face's Transformers, PyTorch Lightning, and Catalyst. PyTorch provides two high-level features: NumPy-like tensor computing and deep neural networks.\n",
    "\n",
    "- [PyTorch Homepage](https://pytorch.org/)\n",
    "- [PyTorch GitHub](https://github.com/pytorch/pytorch)\n",
    "- [PyTorch Forums](https://discuss.pytorch.org/)\n",
    "\n",
    "## Why PyTorch\n",
    "\n",
    "- Supported by Meta\n",
    "- Works well on Windows, Linux, and Mac\n",
    "- Excellent GPU support\n",
    "- Python is an easy to learn programming language\n",
    "- Python is extremely popular in the data science community\n",
    "\n",
    "## Deep Learning Tools\n",
    "\n",
    "PyTorch is not the only game in town. The biggest competitor to PyTorch is TensorFlow/Keras. Listed below are some of the deep learning toolkits actively being supported:\n",
    "\n",
    "- **[TensorFlow](https://www.tensorflow.org/)** - Google's deep learning API. The focus of this class, along with Keras.\n",
    "- **[Keras](https://keras.io/)** - Acts as a higher-level to Tensorflow.\n",
    "- **[PyTorch](https://pytorch.org/)** - PyTorch is an open-source machine learning library based on the Torch library, used for computer vision and natural language applications processing. Facebook's AI Research lab primarily develops PyTorch.\n",
    "\n",
    "Other deep learning tools:\n",
    "\n",
    "- **[Deeplearning4J](http://deeplearning4j.org/)** - Java-based. Supports all major platforms. GPU support in Java!\n",
    "- **[H2O](http://www.h2o.ai/)** - Java-based.\n",
    "\n",
    "In my opinion, the two primary Python libraries for deep learning are PyTorch and Keras. Generally, PyTorch requires more lines of code to perform the deep learning applications presented in this course. This trait of PyTorch gives Keras an easier learning curve than PyTorch. However, if you are creating entirely new neural network structures in a research setting, PyTorch can make for easier access to some of the low-level internals of deep learning.\n",
    "\n",
    "## Using PyTorch Directly\n",
    "\n",
    "PyTorch is also a low-level mathematics API, similar to [NumPy](http://www.numpy.org/). However, unlike Numpy, PyTorch is built for deep learning. PyTorch compiles these compute graphs into highly efficient C++/[CUDA](https://en.wikipedia.org/wiki/CUDA) code.\n",
    "\n",
    "## PyTorch Linear Algebra Examples\n",
    "\n",
    "PyTorch is a library for linear algebra, other components of PyTorch are a higher-level abstraction for neural networks that you build upon the lower level linear algebra.\n",
    "\n",
    "PyTorch can compute on a GPU, CPU, or other advanced compute device. If you are using a Mac, PyTorch is now adding additional support for Apple silicone (M1, M2, M3, etc). For apple support we will use Metal Performance Shaders (MPS). For this course, we assume you will utilize a GPU (cuda), CPU, or MPS. The following code detects the available device and defines the **device** variable that the following code will use for computation. For parts of this course that I know do not work for MPS, we will fall back to CPU. [CUDA](https://en.wikipedia.org/wiki/CUDA) is an NVIDIA standard for accessing GPU capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "istrQO-2-1DK",
    "outputId": "3de2f86d-f197-4659-8e26-0449d74badf7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Make use of a GPU or MPS (Apple) if one is available.\n",
    "has_mps = torch.backends.mps.is_built()\n",
    "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsr6Or3oHTDu"
   },
   "source": [
    "Now that we defined a compute device, I will demonstrate some basic linear algebra that directly employs PyTorch and does not implement a neural network. We begin with a the multiplication of a row and column matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bkh9pHqPCtiO",
    "outputId": "d09d973b-4e80-4841-9f41-e20232eb520c"
   },
   "outputs": [],
   "source": [
    "# Create a Constant op that produces a 1x2 matrix.  The op is\n",
    "# added as a node to the default graph.\n",
    "#\n",
    "# The value returned by the constructor represents the output\n",
    "# of the Constant op.\n",
    "matrix1 = torch.tensor([[3.0, 3.0]], device=device)\n",
    "\n",
    "# Create another Constant that produces a 2x1 matrix.\n",
    "matrix2 = torch.tensor([[2.0], [2.0]], device=device)\n",
    "\n",
    "# Create a Matmul op that takes 'matrix1' and 'matrix2' as inputs.\n",
    "# The returned value, 'product', represents the result of the matrix\n",
    "# multiplication.\n",
    "product = torch.mm(matrix1, matrix2)\n",
    "\n",
    "print(product)\n",
    "print(float(product))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pMrXqwskCtiP"
   },
   "source": [
    "This example multiplied two PyTorch tensors. You can see that we created each tensor on the appropriate device, either the GPU or CPU. Next, we will see how to subtract a constant from a variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qKyFCaoTCtiP",
    "outputId": "a1234aec-3533-4d18-cb16-2ea2314877de"
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 2.0], device=device)\n",
    "a = torch.tensor([3.0, 3.0], device=device)\n",
    "\n",
    "# Add an op to subtract 'a' from 'x'.  Run it and print the result\n",
    "sub = torch.subtract(x, a)\n",
    "print(sub)\n",
    "# Use cpu() in case tensor was on GPU.\n",
    "print(sub.cpu().numpy())\n",
    "# ==> [-2. -1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epQ9LrM6CtiP"
   },
   "source": [
    "Of course, variables are only helpful if we can change their values. The program can accomplish this change in value by calling the assign function. To use Numpy, we must first bring the tensor back to the CPU with the **cpu()** command. Next, we call **numpy()** to access the tensor as a Numpy array. If we were already on the CPU, this function has no effect and returns the already CPU-resident tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vtnW5aU-CtiP"
   },
   "outputs": [],
   "source": [
    "x[0] = 4.0\n",
    "x[1] = 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHwJP8MjCtiQ"
   },
   "source": [
    "The program can now perform the subtraction with this new value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e26Fe-GCtiQ",
    "outputId": "98777e96-67c5-4a60-ff5b-fbffd9be4dda"
   },
   "outputs": [],
   "source": [
    "sub = torch.subtract(x, a)\n",
    "print(sub)\n",
    "print(sub.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rq61YFBYCtiQ"
   },
   "source": [
    "In the next section, we will see a PyTorch example that has nothing to do with neural networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMVIS9pBCtiQ"
   },
   "source": [
    "## PyTorch Mandelbrot Set Example\n",
    "\n",
    "Next, we examine another example where we use PyTorch directly. To demonstrate that PyTorch is mathematical and does not only provide neural networks, we will also first use it for a non-machine learning rendering task. The code presented here can render a [Mandelbrot set](https://en.wikipedia.org/wiki/Mandelbrot_set).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9rEFmqbXsfME"
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "# Take a NumPy array and render it as a Mandelbrot.\n",
    "def render(a):\n",
    "    a_cyclic = (a * 0.3).reshape(list(a.shape) + [1])\n",
    "    img = np.concatenate(\n",
    "        [\n",
    "            10 + 20 * np.cos(a_cyclic),\n",
    "            30 + 50 * np.sin(a_cyclic),\n",
    "            155 - 80 * np.cos(a_cyclic),\n",
    "        ],\n",
    "        2,\n",
    "    )\n",
    "    img[a == a.max()] = 0\n",
    "    a = img\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = BytesIO()\n",
    "    return PIL.Image.fromarray(a)\n",
    "\n",
    "\n",
    "# Loop through the render cycles for. Mandlebrot plot.\n",
    "def mandelbrot_helper(grid_c, current_values, counts, cycles):\n",
    "    for i in range(cycles):\n",
    "        # The Mandlebrot formula\n",
    "        temp = current_values * current_values + grid_c\n",
    "        not_diverged = torch.abs(temp) < 4\n",
    "        current_values.copy_(temp)\n",
    "        counts.copy_(torch.add(counts, not_diverged.double()))\n",
    "\n",
    "\n",
    "# Render a Mandelbrot plot at the specified location, zoom, and render cycles.\n",
    "def mandelbrot(render_size, center, zoom, cycles):\n",
    "    f = zoom / render_size[0]\n",
    "\n",
    "    real_start = center[1] - (render_size[1] / 2) * f\n",
    "    real_end = real_start + render_size[1] * f\n",
    "    imag_start = center[0] - (render_size[0] / 2) * f\n",
    "    imag_end = imag_start + render_size[0] * f\n",
    "\n",
    "    real_range = torch.arange(\n",
    "        real_start, real_end, f, dtype=torch.float32, device=device\n",
    "    )\n",
    "    imag_range = torch.arange(\n",
    "        imag_start, imag_end, f, dtype=torch.float32, device=device\n",
    "    )\n",
    "    real, imag = torch.meshgrid(real_range, imag_range, indexing=\"ij\")\n",
    "    grid_c = torch.complex(imag, real)\n",
    "    current_values = torch.clone(grid_c)\n",
    "    counts = torch.Tensor(torch.zeros_like(grid_c, dtype=torch.float32))\n",
    "\n",
    "    mandelbrot_helper(grid_c, current_values, counts, cycles)\n",
    "    return counts.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O77aOTEDrWRU"
   },
   "source": [
    "With the above code defined, we can now calculate and render a Mandlebrot plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "t3ZfV8A_p_5j",
    "outputId": "02c7b806-42a1-4e97-ad7e-1df103152156"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Pytorch does not currently support complex numbers on MPS (as of 2024-01-07)\n",
    "temp_device = device\n",
    "if device == \"mps\":\n",
    "    device = \"cpu\"\n",
    "\n",
    "counts = mandelbrot(\n",
    "    # render_size=(1920,1080), # HD\n",
    "    render_size=(640, 480),\n",
    "    center=(-0.5, 0),\n",
    "    zoom=4,\n",
    "    cycles=200,\n",
    ")\n",
    "\n",
    "img = render(counts)\n",
    "print(img.size)\n",
    "\n",
    "# restore device\n",
    "device = temp_device\n",
    "\n",
    "# display image\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZeWypKgGCtiR"
   },
   "source": [
    "Mandlebrot rendering programs are both simple and infinitely complex at the same time. This view shows the entire Mandlebrot universe simultaneously, as a view completely zoomed out. However, if you zoom in on any non-black portion of the plot, you will find infinite hidden complexity.\n",
    "\n",
    "## Simple PyTorch Regression: MPG\n",
    "\n",
    "This example shows how to encode the MPG dataset for regression and predict values. We will see if we can predict the miles per gallon (MPG) for a car based on the car's weight, cylinders, engine size, and other features. We will begin by reading the MPG dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "szrd-36UE_ZA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Read the MPG dataset.\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/auto-mpg.csv\", na_values=[\"NA\", \"?\"]\n",
    ")\n",
    "\n",
    "cars = df[\"name\"]\n",
    "\n",
    "# Handle missing value\n",
    "df[\"horsepower\"] = df[\"horsepower\"].fillna(df[\"horsepower\"].median())\n",
    "\n",
    "# Pandas to Numpy\n",
    "x = df[\n",
    "    [\n",
    "        \"cylinders\",\n",
    "        \"displacement\",\n",
    "        \"horsepower\",\n",
    "        \"weight\",\n",
    "        \"acceleration\",\n",
    "        \"year\",\n",
    "        \"origin\",\n",
    "    ]\n",
    "].values\n",
    "y = df[\"mpg\"].values  # regression\n",
    "\n",
    "# Numpy to PyTorch\n",
    "x = torch.tensor(x, device=device, dtype=torch.float32)\n",
    "y = torch.tensor(y, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Af0KuIwCFOMZ"
   },
   "source": [
    "We use Pandas to load the CSV file, as previously demonstrated. We will save the names of the cars, though the car names do not help predict the MPG. Horsepower does have missing values, so we substitute the median value for any missing values. Next, we convert Pandas to NumPy, and Numpy to PyTorch. We select only the fields that we wish to use to predict. As previously discussed, we designed the Net class to detect the size of this data and add the appropriate count of input neurons.\n",
    "\n",
    "You define your neural network in the **Sequence** above. We will see later that you may also construct a neural network using a Python class. In this case, we have a neural network with an input layer equal to the number of inputs you specify from the MPG dataset. The neural network connects these inputs to 50 neurons in the first hidden layer, which are connected to 25 neurons in the second layer. The output neuron count for a layer must always match the input count of the next layer.\n",
    "\n",
    "For this book, we will generally always use the Relu activation function for hidden layers. The output layer will use no transfer function for a regression neural network like this MPG example. For classification, we use the logistic for binary classification (just two classes) or log softmax for two or more classes.\n",
    "\n",
    "For the neural network to perform correctly, everything must align. The **sequence** must specify all layers with the same number of outputs as inputs for each connection. \n",
    "\n",
    "We are ready to create the neural network, loss function, and optimizer class with the data loaded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tY8-elD1FIsk"
   },
   "outputs": [],
   "source": [
    "# Create the neural network\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(x.shape[1], 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 25),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(25, 1)\n",
    ")\n",
    "\n",
    "# PyTorch 2.0 Model Compile (improved performance), but does not work as well on MPS\n",
    "#model = torch.compile(model,backend=\"aot_eager\").to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function for regression\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41vdE4UqFO-p"
   },
   "source": [
    "We create the neural network with one input equal to the number of columns in the x-input data. We specify one output neuron which will predict the MPG. Next, we define MSELoss as the error function, which is a common choice for regression. We will use the Adam optimizer with a learning rate of 0.01 to train the network. Adam is a common choice, and 0.01 is a good start for a learning rate. The learning rate should never be above 1.0. Too large of a learning rate will fail to learn the problem thoroughly, and too low of a learning rate will take a long time to train. We will see more advanced methods for choosing the learning rate, including schedules that change it throughout training.\n",
    "\n",
    "With the objects created, we can now train the neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XapHMWRrFKfJ",
    "outputId": "3520d6a7-fec5-4c82-b516-b22a2cf0be5d"
   },
   "outputs": [],
   "source": [
    "# Train for 1000 epochs.\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x).flatten()\n",
    "    loss = loss_fn(out, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Display status every 100 epochs.\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqUK73GtE5jU"
   },
   "source": [
    "We now loop over 1,000 epochs and train the neural network; we define an epoch as one complete pass over the training set. We zero the gradients, so training from the previous epoch does not influence the current epoch. We present the entire training set to the model as one large batch. Later we will see more advanced ways to segment the data. We apply the loss function and use backpropagation to calculate the gradients to update the neural network weights.\n",
    "\n",
    "## Introduction to Neural Network Hyperparameters\n",
    "\n",
    "This network includes several hidden layers, with 50 and 25 neurons each. You might be wondering how the programmer chose these numbers. Selecting a hidden neuron structure is one of the most common questions about neural networks. Unfortunately, there is no right answer. These are hyperparameters. They are settings that can affect neural network performance, yet there are no clearly defined means of setting them.\n",
    "\n",
    "In general, more hidden neurons mean more capability to fit complex problems. However, too many neurons can lead to overfitting and lengthy training times. Too few can lead to underfitting the problem and will sacrifice accuracy. Also, how many layers you have is another hyperparameter. In general, more layers allow the neural network to perform more of its feature engineering and data preprocessing. But this also comes at the expense of training times and the risk of overfitting. In general, you will see that neuron counts start larger near the input layer and tend to shrink towards the output layer in a triangular fashion.\n",
    "\n",
    "Some techniques use machine learning to optimize these values. These will be discussed in [Module 8.3](t81_558_class_08_3_pytorch_hyperparameters.ipynb).\n",
    "\n",
    "## Regression Prediction\n",
    "\n",
    "Next, we will perform actual predictions. The program assigns these predictions to the **pred** variable. These are all MPG predictions from the neural network. Notice that this is a 2D array? You can always see the dimensions of what PyTorch returns by printing out **pred.shape**. Neural networks can return multiple values, so the result is always an array. Here the neural network only returns one value per prediction (there are 398 cars, so 398 predictions). However, a 2D range is needed because the neural network has the potential of returning more than one value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbErLyX_CtiR",
    "outputId": "25921c8c-6b2f-4cb9-dd5e-b7dcca494c73"
   },
   "outputs": [],
   "source": [
    "pred = model(x)\n",
    "print(f\"Shape: {pred.shape}\")\n",
    "print(pred[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jk_lWnScCtiR"
   },
   "source": [
    "We would like to see how good these predictions are. We know the correct MPG for each car so we can measure how close the neural network was. We will first see how we calculate RMSE with standard Sklearn metrics. To utilize Sklearn we must bring the predictions back to the CPU and deatch them from the neural network graph. The following code accomplishes this with **cpu().detach()**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vrY0Vs9oCtiR",
    "outputId": "f6d41314-5cd7-4209-f6ec-c17235414593"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Measure RMSE error.  RMSE is common for regression.\n",
    "score = np.sqrt(metrics.mean_squared_error(pred.cpu().detach(), y.cpu().detach()))\n",
    "print(f\"Final score (RMSE): {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkLxHFUmMcD7"
   },
   "source": [
    "We can accomplish the same task entirely within PyTorch with less code. It is important to know how to perform these calculations both with PyTorch and Scikit-learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atZ8m2bGMnz9",
    "outputId": "66e2e5b2-a226-4ff2-c14c-1a24619c3759"
   },
   "outputs": [],
   "source": [
    "score = torch.sqrt(torch.nn.functional.mse_loss(pred.flatten(), y))\n",
    "print(f\"Final score (RMSE): {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3yqZwhnCtiS"
   },
   "source": [
    "The number printed above is the average number of predictions above or below the expected output. We can also print out the first ten cars with predictions and actual MPG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tl7hv8NnCtiS",
    "outputId": "a0d37235-031b-4a74-a122-1a4fd08b5c0b"
   },
   "outputs": [],
   "source": [
    "# Sample predictions\n",
    "for i in range(10):\n",
    "    print(f\"{i+1}. Car name: {cars[i]}, MPG: {y[i]}, \" + f\"predicted MPG: {pred[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_dpgVtfCtiS"
   },
   "source": [
    "## Simple TensorFlow Classification: Iris\n",
    "\n",
    "Classification is how a neural network attempts to classify the input into one or more classes. The simplest way of evaluating a classification network is to track the percentage of training set items classified incorrectly. We typically score human results in this manner. For example, you might have taken multiple-choice exams in school in which you had to shade in a bubble for choices A, B, C, or D. If you chose the wrong letter on a 10-question exam, you would earn a 90%. In the same way, we can grade computers; however, most classification algorithms do not merely choose A, B, C, or D. Computers typically report a classification as their percent confidence in each class. Figure 3.EXAM shows how a computer and a human might respond to question number 1 on an exam.\n",
    "\n",
    "**Figure 3.EXAM: Classification Neural Network Output**\n",
    "![Classification Neural Network Output](https://data.heatonresearch.com/images/wustl/class/class-multi-choice.png \"Classification Neural Network Output\")\n",
    "\n",
    "As you can see, the human test taker marked the first question as \"B.\" However, the computer test taker had an 80% (0.8) confidence in \"B\" and was also somewhat sure with 10% (0.1) on \"A.\" The computer then distributed the remaining points to the other two. In the simplest sense, the machine would get 80% of the score for this question if the correct answer were \"B.\" The computer would get only 5% (0.05) of the points if the correct answer were \"D.\"\n",
    "\n",
    "We previously saw how to train a neural network to predict the MPG of a card. Based on four measurements, we will now see how to predict a class, such as the type of iris flower. The code to classify iris flowers is similar to MPG; however, there are several important differences:\n",
    "\n",
    "- The output neuron count matches the number of classes (in the case of Iris, 3).\n",
    "- The **LogSoftmax** transfer function is utilized by the output layer.\n",
    "- The loss function is **CrossEntropyLoss**.\n",
    "- We call the **train** function to inform PyTorch that we are now in training mode.\n",
    "- Later, we call the **eval** function to inform PyTorch that we are done training and are evaluating the network.\n",
    "\n",
    "Softmax is commonly used in classification tasks because it allows us to transform the output of a model into a probability distribution over multiple classes. By applying the softmax function to a model's logits (raw outputs), we obtain normalized probabilities that sum up to one, indicating the likelihood of each class. This technique lets us interpret the model's predictions as confidence scores for different classes and make decisions based on the highest probability.\n",
    "\n",
    "Log softmax, on the other hand, offers several advantages over regular softmax. One advantage is that it helps to alleviate numerical instability issues that can occur when dealing with small or large values in softmax computations. By taking the logarithm of the softmax probabilities, we work in the logarithmic domain, which can improve numerical stability and prevent overflow or underflow errors. Log softmax is also useful when applying the negative log-likelihood loss function, as it simplifies the mathematical calculations by eliminating the need to compute the actual probabilities. This technique is particularly beneficial when training neural networks as it simplifies optimization. Log softmax provides a practical and efficient way to handle classification problems, offering numerical stability and simplifying loss computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aLp65T9JCtiS",
    "outputId": "28975453-2c5f-43fc-eabd-2b8b5f522d47"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"https://data.heatonresearch.com/data/t81-558/iris.csv\", na_values=[\"NA\", \"?\"]\n",
    ")\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "x = df[[\"sepal_l\", \"sepal_w\", \"petal_l\", \"petal_w\"]].values\n",
    "y = le.fit_transform(df[\"species\"])\n",
    "species = le.classes_\n",
    "\n",
    "x = torch.tensor(x, device=device, dtype=torch.float32)\n",
    "y = torch.tensor(y, device=device, dtype=torch.long)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(x.shape[1], 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 25),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(25, len(species)),\n",
    "    #nn.LogSoftmax(dim=1), # Implied by use of CrossEntropyLoss\n",
    ")\n",
    "\n",
    "# PyTorch 2.0 Model Compile (improved performance), but does not work as well on MPS\n",
    "#model = torch.compile(model,backend=\"aot_eager\").to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # cross entropy loss\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x)\n",
    "    # Note: CrossEntropyLoss combines nn.LogSoftmax() and nn.NLLLoss() so don't use Softmax in the model\n",
    "    loss = criterion(out, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QPM30WdBCtiS",
    "outputId": "185a1859-a5dc-4251-a947-80a4246cc594"
   },
   "outputs": [],
   "source": [
    "# Print out number of species found:\n",
    "\n",
    "print(species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dM8-xyDxCtiS"
   },
   "source": [
    "Now that you have a neural network trained, we would like to be able to use it. The following code makes use of our neural network. Exactly like before, we will generate predictions. Notice that three values come back for each of the 150 iris flowers. There were three types of iris (Iris-setosa, Iris-versicolor, and Iris-virginica). We call the **eval** function to inform PyTorch that we are no longer training and wish to evaluate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3YzlVpw-CtiS",
    "outputId": "2edf87f0-b57a-4f49-b7fc-78ac1c802a19"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = model(x)\n",
    "print(f\"Shape: {pred.shape}\")\n",
    "print(pred[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCay-JrvCtiS"
   },
   "source": [
    "If you would like to turn of scientific notation, the following line can be used:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nXZne7ZICtiS"
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOvMqI7QCtiS"
   },
   "source": [
    "Now we see these values rounded up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9PSDexjCtiS",
    "outputId": "df299de1-6686-44cb-a894-9b20639c0d10"
   },
   "outputs": [],
   "source": [
    "print(pred[0:10].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDC7hxqECtiS"
   },
   "source": [
    "Usually, the program considers the column with the highest prediction to be the prediction of the neural network. It is easy to convert the predictions to the expected iris species. The argmax function finds the index of the maximum prediction for each row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "367mbx_PCtiT",
    "outputId": "c022460c-ec3e-491d-85a8-f9b9f0f73776"
   },
   "outputs": [],
   "source": [
    "_, predict_classes = torch.max(pred, 1)\n",
    "print(f\"Predictions: {predict_classes}\")\n",
    "print(f\"Expected: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrcy0Q4xCtiT"
   },
   "source": [
    "Of course, it is straightforward to turn these indexes back into iris species. We use the species list that we created earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NTORTvygCtiT",
    "outputId": "7be0ba26-172c-4b5d-9353-7b6b349cc879"
   },
   "outputs": [],
   "source": [
    "print(species[predict_classes[1:10].cpu().detach()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ljez1ZRACtiT"
   },
   "source": [
    "Accuracy might be a more easily understood error metric. It is essentially a test score. For all of the iris predictions, what percent were correct? The downside is it does not consider how confident the neural network was in each prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zth2S2OcCtiT",
    "outputId": "64510162-96ed-45f7-b72c-8c22e2aa127a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "correct = accuracy_score(y.cpu().detach(), predict_classes.cpu().detach())\n",
    "print(f\"Accuracy: {correct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jY07aiLICtiT"
   },
   "source": [
    "The code below performs two ad hoc predictions. The first prediction is a single iris flower, and the second predicts two iris flowers. Notice that the **argmax** in the second prediction requires **axis=1**? Since we have a 2D array now, we must specify which axis to take the **argmax** over. The value **axis=1** specifies we want the max column index for each row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZUSWVGnCtiT",
    "outputId": "e7e4be75-b618-4f1a-b7f3-9cdcafcd9a14"
   },
   "outputs": [],
   "source": [
    "sample_flower = torch.tensor([[5.0, 3.0, 4.0, 2.0]], device=device)\n",
    "pred = model(sample_flower)\n",
    "print(pred)\n",
    "_, predict_classes = torch.max(pred, 1)\n",
    "print(f\"Predict that {sample_flower} is: {species[predict_classes]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENSZaaRICtiT"
   },
   "source": [
    "You can also predict two sample flowers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdSSkkmwCtiT",
    "outputId": "69bcfb15-5964-46d0-b47a-7d8114d3ee95"
   },
   "outputs": [],
   "source": [
    "sample_flower = torch.tensor(\n",
    "    [[5.0, 3.0, 4.0, 2.0], [5.2, 3.5, 1.5, 0.8]], device=device\n",
    ")\n",
    "pred = model(sample_flower).to(device)\n",
    "print(pred)\n",
    "_, predict_classes = torch.max(pred, 1)\n",
    "print(f\"Predict that these two flowers {sample_flower} \")\n",
    "print(f\"are: {species[predict_classes.cpu().detach()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice that the output is negative, rather than probabilities that add to 1.0. You can see that each result is 3 numbers, ideally these would be the probability that the input was each of the three type of iris flower. This is due to the log softmax function we used. To convert these values to traditional probabilities just use torch.exp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.exp(pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
