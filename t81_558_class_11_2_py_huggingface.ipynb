{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CF2edFAI4Uj"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/app_deep_learning/blob/main/t81_558_class_11_2_py_huggingface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvbM-RwHI4Ul"
   },
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "**Module 11: Natural Language Processing with Hugging Face**\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dE7A-0aI4Ul"
   },
   "source": [
    "# Module 11 Material\n",
    "\n",
    "* Part 11.1: Introduction to Hugging Face [[Video]](https://www.youtube.com/watch?v=PzuL84ksRuE&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_11_1_hf.ipynb)\n",
    "* **Part 11.2: Hugging Face in Python** [[Video]](https://www.youtube.com/watch?v=tkGIF4CFoV4&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_11_2_py_huggingface.ipynb)\n",
    "* Part 11.3: Hugging Face Tokenizers [[Video]](https://www.youtube.com/watch?v=Cz2nvfK28eI&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_11_3_tokenizers.ipynb)\n",
    "* Part 11.4: Hugging Face Datasets [[Video]](https://www.youtube.com/watch?v=yLlCZLzE2XU&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_11_4_hf_datasets.ipynb)\n",
    "* Part 11.5: Training Hugging Face Models [[Video]](https://www.youtube.com/watch?v=7YZOik5S3vs&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_11_5_hf_train.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Z4A091yI4Um"
   },
   "source": [
    "# Google CoLab Instructions\n",
    "\n",
    "The following code checks if Google CoLab is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RJmzbge9I4Um",
    "outputId": "f98a353c-05b4-4678-8b99-9dfae65e673e"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdNN6e45I4Un"
   },
   "source": [
    "# Part 11.2: Hugging Face Python Intro\n",
    "\n",
    "Transformers have become a mainstay of natural language processing. This module will examine the [Hugging Face](https://huggingface.co/) Python library for natural language processing, bringing together pretrained transformers, data sets, tokenizers, and other elements. Through the Hugging Face API, you can quickly begin using sentiment analysis, entity recognition, language translation, summarization, and text generation.\n",
    "\n",
    "Colab does not install Hugging face by default. Whether installing Hugging Face directly into a local computer or utilizing it through Colab, the following commands will install the library.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3jGET2abMjcl",
    "outputId": "ec7e97eb-5b23-4d25-fade-9e102834d94a"
   },
   "outputs": [],
   "source": [
    "# HIDE OUTPUT\n",
    "!pip install transformers\n",
    "!pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsGnO6OOa74p"
   },
   "source": [
    "Now that we have Hugging Face installed, the following sections will demonstrate how to apply Hugging Face to a variety of everyday tasks. After this introduction, the remainder of this module will take a deeper look at several specific NLP tasks applied to Hugging Face.\n",
    "\n",
    "## Sentiment Analysis\n",
    "\n",
    "Sentiment analysis uses natural language processing, text analysis, computational linguistics, and biometrics to identify the tone of written text. Passages of written text can be into simple binary states of positive or negative tone. More advanced sentiment analysis might classify text into additional categories: sadness, joy, love, anger, fear, or surprise.\n",
    "\n",
    "To demonstrate sentiment analysis, we begin by loading sample text, Shakespeare's [18th sonnet](https://en.wikipedia.org/wiki/Sonnet_18), a famous poem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lhTp-h2TLuH1"
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "# Read sample text, a poem\n",
    "URL = \"https://data.heatonresearch.com/data/t81-558/\"\\\n",
    "    \"datasets/sonnet_18.txt\"\n",
    "f = urlopen(URL)\n",
    "text = f.read().decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p257hMO_fier"
   },
   "source": [
    "Usually, you have to preprocess text into embeddings or other vector forms before presentation to a neural network. Hugging Face provides a pipeline that simplifies this process greatly. The pipeline allows you to pass regular Python strings to the transformers and return standard Python values. \n",
    "\n",
    "We begin by loading a text-classification model. We do not specify the exact model type wanted, so Hugging Face automatically chooses a network from the Hugging Face hub named:\n",
    "\n",
    "* distilbert-base-uncased-finetuned-sst-2-english\n",
    "\n",
    "To specify the model to use, pass the model parameter, such as:\n",
    "\n",
    "```\n",
    "pipe = pipeline(model=\"roberta-large-mnli\")\n",
    "```\n",
    "\n",
    "The following code loads a model pipeline and a model for sentiment analysis.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163,
     "referenced_widgets": [
      "43b445cf7c034e19835852fd4eb0dfdf",
      "7eed8768a34d4ef083efbd46d2b8fe4d",
      "49e49b94bf204202ac99d7c524ea9325",
      "cbc8ab2edb39478b8f41aec01d4dae2c",
      "6133e19b9fee4b7c95bcef7afc103087",
      "d47070d2a61140f5ba4867419bb8d890",
      "e5fcdc0e87164b17b7d879fbc7db00e9",
      "eb39f5f29cb24a73b479996374e0c086",
      "573207a8c694490d97b53af6062ed3fa",
      "768f3148134643c29959f4d6632814ce",
      "88c6c931e6524cff940fcb8e4f5341eb",
      "b8985237d35b43bfa74c39f841f5fbcc",
      "c71bc3aeaddd419fb09aff268f272386",
      "5daf69b6adeb4c0f87bc6ee48d5e8637",
      "3337796847dc45bdb292df8c16fa63b7",
      "c0eba355f06f4203881cafab58363d9c",
      "cd1c47d4bc98456982d09f291ed0ec76",
      "5fa37f8f788947599ceb8ad92a5c5782",
      "693d8958ba424757838a032b04a411bd",
      "e6fa5cb0d50f4a51a4452c30ed69da32",
      "0ee0df46d3654b71839b8ca715fc4e77",
      "7fdf8d7690ab4273a9e470f63967f467",
      "2ff77f69edb7486d9569fe1b6879c9da",
      "51246f02e6cf44f5ad1f500d1537a3ae",
      "ad36470539ec4531b1338ecbcdea280c",
      "d79c4eac4a10453aa83266c761c10949",
      "dc0b6678f83a4011a7cd80a764b2249c",
      "8a4de3d5d4be4973bf0e3c0c69c7b951",
      "a62d83482653481f8c8b6a6d97fd78fc",
      "f862df8fa76248dfa9870b807c63ca25",
      "6cf7b58d409b412abcd09e8a00d1d2a7",
      "d1088be8de4c4f61ac689e056e27828a",
      "14cd2bf5a67d491dbbca68f5c63b34ab",
      "193825fe107f4d9995a1c42528705a63",
      "5105d3df90584f46ac2a8b5702df30d7",
      "ed8b73a68810482789eedf73f521e3bf",
      "bd649abbec894affb8b00196bda5d1e4",
      "0eecd1a6716a4141a488e69d9436c03b",
      "b87ee21621144babb5f246ceec2538e0",
      "eb599c1318d84155af26f4c152c3402c",
      "b4d9119ded644c35a564ed469829835c",
      "dd402b5abfd44b3883a6f7a156b48728",
      "84b14fc45a8249da9c193f3f04fcbde5",
      "7789e638c1f64800b91538c2403a84d3"
     ]
    },
    "id": "T5pCmo2RMEm3",
    "outputId": "65f9fdf6-b6d7-4795-bc32-4e87d23850b8"
   },
   "outputs": [],
   "source": [
    "# HIDE OUTPUT\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfztK2uW1BzC"
   },
   "source": [
    "We can now display the sentiment analysis results with a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "rBc2vFu6ZuKq",
    "outputId": "c2a7a84b-e1be-4981-9365-26f55a71b2e5"
   },
   "outputs": [],
   "source": [
    "outputs = classifier(text)\n",
    "pd.DataFrame(outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8po2DD_bkXA"
   },
   "source": [
    "As you can see, the poem was considered 0.98 positive.\n",
    "\n",
    "## Entity Tagging\n",
    "\n",
    "Entity tagging is the process that takes source text and finds parts of that text that represent entities, such as one of the following:\n",
    "\n",
    "* Location (LOC) \n",
    "* Organizations (ORG)\n",
    "* Person (PER)\n",
    "* Miscellaneous (MISC)\n",
    "\n",
    "The following code requests a \"named entity recognizer\" (ner) and processes the specified text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183,
     "referenced_widgets": [
      "41760795654445a5bdc65da1cab2f446",
      "3d63c3043e0141379808e8f7555f3591",
      "73869005c0d84e04b15c36160d118f9e",
      "ee56d45ebb064d7aaee65d59f19a315c",
      "31592ee37ba7492c8c8d0f401ffa2e5e",
      "ed03f8f2324544f8b28d652eef06c2e6",
      "7ca5acb61b7a42869df44d7a6ce92088",
      "94e813310aa14c9ab95bc7001003f5ca",
      "3d79b08772234fc69f8fe5a4f7ea2d5d",
      "1bb7610fb9464b3da3c2b9601ed1cdfa",
      "b6da4d19e6794633b2c181a062876b0f",
      "705c74aa508b4d598a964a823b026938",
      "7e605a55ad2b4da095c8d9c0388e66ab",
      "b8394b0535cb4a549dae982e20480e53",
      "4394feaaf47f472ab423d41c30ace43b",
      "1e1c444d710544b3917b062e384e7493",
      "05c18bcf6e134d1ebfb4161d6661c114",
      "242b670fe05944079da4fe36334354c3",
      "9c7e4022f34f4326bf25901a17ded935",
      "3cd55021fa3a448a8dccd6152d277363",
      "14f3455894054ec18a30ff4e579d03b4",
      "9ad4c7fdb3f94c4bb25262dcca3650f7",
      "d81ab003ec484929b34fc66b55e56839",
      "45f5129b70ef4a1fbbea7612e0e9389b",
      "15d259d5b7c54e6bb287991d1845e2eb",
      "78f0394fbb6c40dc9c379b770b6e82a4",
      "6c17206f950543c4ba643ad6c4e73759",
      "b9d15e3f8c9548c3bc31ccce89970d80",
      "35a6c11d376b45f397cb01e74bca3e7a",
      "294572b44783447a9c16648884ddafd1",
      "ae192e7b5e3e4bf4ab62b90c37d186e9",
      "7c3ff438cb8243fe86d688a75d15e035",
      "dda98773e9234e87be82b82e5fe6f020",
      "31123d802d9c440e8a367cc3f5f4777b",
      "8c8cfaad29ef4d1ea2d1fa4356d81a96",
      "a567f93387624ccba236d0036e3eddc1",
      "1f00cbee5cb6443381bb3d3bd4f59d95",
      "0337ddbf18ec4708882fc393cf9982f7",
      "604f503669d14b17820369de16ec278e",
      "9ba4a21395b94459ac8fd73ae97cc209",
      "326f6701effa4c7da92d12d24ca58212",
      "5a7cda3676314953bb9447bcf4957e94",
      "39dd083553964a09a6442153f0bedcfc",
      "9e87c35f47b243d69301d2ecf6f2f725"
     ]
    },
    "id": "dgwmlVBOM4T_",
    "outputId": "47d4ed52-eb67-41d1-d1dc-62017077c063"
   },
   "outputs": [],
   "source": [
    "# HIDE OUTPUT\n",
    "text2 = \"Abraham Lincoln was a president who lived in the United States.\"\n",
    "\n",
    "tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dD3H6LRu2_6e"
   },
   "source": [
    "We similarly view the results as a Pandas data frame. As you can see, the person (PER) of Abraham Lincoln and location (LOC) of the United States is recognized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "Kb6IXZIWZ2fB",
    "outputId": "fd0048b3-fcf6-4897-9f92-7fa87e71280e"
   },
   "outputs": [],
   "source": [
    "outputs = tagger(text2)\n",
    "pd.DataFrame(outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0MMmvJIbok_"
   },
   "source": [
    "## Question Answering\n",
    "\n",
    "Another common task for NLP is question answering from a reference text. We load such a model with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195,
     "referenced_widgets": [
      "1ab15a82c7574c709d73ffb6d2aaa7ba",
      "1374a4ecd81b4fdf83711ff06356992d",
      "2dfd221ccfc04dc3b74dc57305293bff",
      "16e01325750843d880435437efbf85e5",
      "57e40ffe2ac04b0cb0717f65f7f2ab8e",
      "332799bd47a64e74a8e24dc8b5dba4b7",
      "2de19b60e5074cdaa61f20c53f3ec439",
      "b254ea5ea8fb4dfc921bb4542121cede",
      "8cf74d74f087416783fd3cea6e272986",
      "8d272479fccb4cc799df306f70518f5f",
      "d6dc5672e767411ca82f672af71ad1d4",
      "0e9e17678b384965a9ed016442e45655",
      "461670fe2c3e4bcdb543e1c4ac7eb803",
      "115d8535ebfb4a3bb53bf59caa8140f8",
      "ce04625bcc6a4a5bb7134966dbbfc01c",
      "f315ce3dcb7d4ff085c6a2b1b499bb3f",
      "00d90ad51b6b46378626dfc82813ebdb",
      "b5c1146061304630bba1dbb4bc3d3abc",
      "2753eca932e048d78775b81ae682b561",
      "37d227310d9b4dd2bc1c6dd3e20cfc02",
      "cebad66c7aac4eb0920915c00dc6acc5",
      "9e308b465384406f8e85d9bebfba8ec6",
      "f7f51383260f4fb6b5465f7171898441",
      "33ccdca918024ad585e6ccbeb170cf86",
      "df8759d8639c4eeab42c6b8e512d7939",
      "ad17595c70754b46af5577028ceca08d",
      "60881a3c37a94982982ef7e76118957d",
      "9b3a9c75769143e999f7ec1fc7209293",
      "b50421d5c3154be3afc6aaba5fc1dc97",
      "efb39afd49504ce095b101bcc73aa1b4",
      "c582321ab08a4358b999d6e893559340",
      "3b635ace6a194ae097366d2cf7347ef9",
      "ecfd89854b0945f28bcc1c5a60201bc0",
      "dceff93046b44783a8497ed4a8648a3c",
      "5cb5bd2403c2446d9efb5dde2c177a8e",
      "645f85e75ac14ac1b6a2833908f9a9cd",
      "99bd3b59a9c44711b98ecac0eb41c118",
      "5a77949eb54947a8b07392c9748ba353",
      "9468986a75d64f159d1238cec2917b7e",
      "4af0aca66f9e496a8c525528b299e07a",
      "2d0eb4a2334d4045908f3e87dd438f70",
      "8fadb4e1556e4e4487560aba330e1fda",
      "e457bdc961b8475382feb31b8493ac37",
      "fc1c53ae09e544b69e93eb72fe137eff",
      "6aaf1b3dfdc549b89bea041865fb4106",
      "10bd4e909b7143eb98b3d9580fe7a561",
      "ebe9cdfb0b28480e99e6add40502ea80",
      "acd278b53710483192a8ece545aa81b6",
      "5912eef058724998934ff9693ac89405",
      "b05300632a374cc0b05b7182517fca35",
      "cc73877507504ab5a8ac9eb0c0391d7b",
      "ff0c0892a0084f74973a43bf40d0a8ca",
      "cc0430a610244fc7979aa7bd30c4c41f",
      "414f3fc6c57a4b04a45190cb847edfd3",
      "dc8db8261ac942be8109de1cd9ae8aef"
     ]
    },
    "id": "uzDdrN3ONgp-",
    "outputId": "b35c26a8-f6d9-494a-e250-d0ee4d5164a4"
   },
   "outputs": [],
   "source": [
    "# HIDE OUTPUT\n",
    "reader = pipeline(\"question-answering\")\n",
    "question = \"What now shall fade?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKN9Pg1O3Rcm"
   },
   "source": [
    "For this example, we will pose the question \"what shall fade\" to Hugging Face for [Sonnet 18](https://en.wikipedia.org/wiki/Sonnet_18). We see the correct answer of \"eternal summer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "eHAZn7yLZ9ph",
    "outputId": "d0be24e2-b236-489f-b147-55b942f7b97b"
   },
   "outputs": [],
   "source": [
    "outputs = reader(question=question, context=text)\n",
    "pd.DataFrame([outputs])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qAiCMSUzbsBE"
   },
   "source": [
    "## Language Translation\n",
    "\n",
    "Language translation is yet another common task for NLP and Hugging Face. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "c15d9366d2fb4081bb22d2b181f58fd2",
      "147ab39cd275424d8481d91382fa5b82",
      "005415ad498e4842b4f31e396d2d41f3",
      "8abb63be539c4d01b3428dae46897459",
      "2e7942ba104e4e90b065ff2044f09fa8",
      "e98195322e144d71b0bb159576ab6a87",
      "fd7bb5fe79fd486e8e68276b52e88665",
      "0811ecd108384e89aa3173f8fde4b36c",
      "beaa2cd298984567879f3eaf35a49c01",
      "f731fb8c6455434d85f3950a7e74f1fa",
      "5ae871cbfc9b44debb5c192660d22f8a",
      "25ca8710daff44ba807100925dee3db0",
      "48e2e1b0a1e34b64ba307bf6cf441ebf",
      "481ee1a6c4794401932cd779c188b973",
      "f27ad57614514a3c966b56ae29135e28",
      "087943700ede42f688006bc293a9acaa",
      "d80e30756cff4e36a26cb04fbcfb555a",
      "e896e4e3c2dc4a5fbce91f91ce75d9da",
      "88ad8523268c4b5ab4f1e4c40536b112",
      "ef9a417dfa9f42f28700a5e4afe609fd",
      "84b64a67e5464588aa7f67f2da397bb8",
      "32ce97be97aa4199beb60a866b47ce06",
      "4408fa21d7e34ba199b150d4bd435347",
      "6d286c0caa5043f2bf9a0d1ab67aea01",
      "b2535901dfc94f90969df564bc8919c2",
      "1501325c4f7f43f09916458b263ceb58",
      "6ae5138727914d27b84cc9c732429004",
      "c8d53be108a24fe8b5c1253f8d4df2ba",
      "3d1901e2186a4b19bb2717f036a89a96",
      "10115fc046664665beb5f2256f529a01",
      "839fea5970c042cfaca7d64976d75576",
      "e90cb26aa50243d88c15c63969eb827e",
      "1fd636d9fdeb42eaaf3c2a21dc88c655",
      "ea6e9709342747089d1fb2bb55b8955f",
      "c9549952253f4578ac7e7c4903f6043d",
      "57f2f9c00dbc49bd8fea1fe2c6338f15",
      "13c82456484a4ba2bfee2bdb0ada75ba",
      "8d06ae81b69447f6a5acbdd149f17fd1",
      "d47a1b61f27b429fa92d229c58cfc989",
      "1b2be941cdab4cd0a1545d1f4d9ccff7",
      "663596920e554c02bdc53bbc9a6f22ed",
      "e35ba4c481c247858e9d9ea3147abd6f",
      "eb96b74027c34e32b7e670ab57d074d3",
      "94d044847f604a2fb21c7fc765c294bb",
      "b7beca11b60c4c44bfdd183aaebc50f2",
      "ca24eb3e83db42b992f2147fb4598829",
      "97ec4841717649a681b54adfd12a0f12",
      "e10888954f1e4ea8bdee8d15fe295045",
      "678a9ddc9c8e4192b107ae156b8c84b4",
      "1988a5b8d63f416fa463e126f5d4f6dd",
      "6ecec7992d794a1f9ffd68f021dcd9b7",
      "bc7334f1e9dd4cab940fbef701bc4a72",
      "066892fd8c8945dea81f558769d70d4c",
      "e7cd9db26cef473fbf876d58d5bd7d8f",
      "7227f922a36f4e238cbe920e207765c7",
      "0265095f16d04bdab445243cf52e61b9",
      "47043c8a093347b5b1ba8c50cdda6e35",
      "e7bc5d1fb6034d1c942475e181c8e201",
      "c52f2850d20e4c5ea501a1b98c2315cc",
      "c11f2dc9aab04e22815185dc840c24e1",
      "e3aa275f0d3c40a5bf4366342f571818",
      "522662dc02d344c59e27a5d54c645c01",
      "b7e0cd0b79fb49058862aa649f5842e8",
      "26a82cb11cbd4767a35a8c3114c80b9f",
      "dda6d5402ac347b2b1651ea742908709",
      "f7f9c35855024171a73a25c6a49cea4c"
     ]
    },
    "id": "4wTcziADOH2j",
    "outputId": "3a251d92-3801-41cf-cc81-1edcf5a9c72c"
   },
   "outputs": [],
   "source": [
    "# HIDE OUTPUT\n",
    "translator = pipeline(\"translation_en_to_de\",\n",
    "                      model=\"Helsinki-NLP/opus-mt-en-de\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mSJ1THpi3VsO"
   },
   "source": [
    "The following code translates Sonnet 18 from English into German."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hQZ_puh4aA_G",
    "outputId": "bd3a0e06-d2e4-430a-89c2-b0df20c7b7f5"
   },
   "outputs": [],
   "source": [
    "outputs = translator(text, clean_up_tokenization_spaces=True,\n",
    "                     min_length=100)\n",
    "print(outputs[0]['translation_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wzu8PC_dbvMd"
   },
   "source": [
    "## Summarization\n",
    "\n",
    "Summarization is an NLP task that summarizes a more lengthy text into just a few sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195,
     "referenced_widgets": [
      "b4ded727b5eb4349a0e33ad277336664",
      "8dcb2d3b41ab4513ac3aca2b7d0cb847",
      "1a1a57161a8f458887aa5056e8f1c61f",
      "23e05651ea0649f78e18a22e932ade53",
      "3b90661171f74b959c7660cdd1993977",
      "6d20453c73754c659cc77a6dacd26193",
      "69f025dc247740b0900c33e66d2154d3",
      "7652daa950204ceaab66b0e6a1039966",
      "44bc9875f5974f5dbb707216c6ad0983",
      "b84750df1ef148caa66ff9cc374f6642",
      "f93a2bbd34844205856ecf785213d7a2",
      "15d683c2a4154b0083ae4d52944daca6",
      "96120e57ea3840919cdbf839ebaea274",
      "9966675c3ebf480a8c458e61ed8c6140",
      "87acee923c0045feb0a1d4f4d247eac6",
      "f039813f28434563b79ef2ae54873162",
      "a4e46c4fc2dc4c05b4217299f57b1cdc",
      "b23b39915c9b4508a2398408bdb954f6",
      "e99d1795beea44a3b28eabb200fc85d9",
      "780a1e2f01514b59859fbb99a27cd66c",
      "f807795d2ee74cd0a479f6b5d12388b8",
      "7a8b77dddf974e4fa21c03e9b8d0f08e",
      "4ffb03dae2524b1b826319a92d26b1fb",
      "3e4c3ac307cd46f087ee1a5376c86932",
      "ab745250709b44029067284271c12290",
      "9f1fe152480042c0878c1cd8a13236c0",
      "4e2431bb18d2467caa87dc3bbb1dcfe8",
      "ead5060478384200adbf19a7a52767a8",
      "e649b9150a00462a943d0506ba732a1a",
      "fdf30be5fcf341c2937c48110e01dc59",
      "e8a55b1d3da249d6a1a2d2e75a1f524e",
      "7abe845dc8764569b110a240e85d5224",
      "cc2accacd9704fd8a2ab7d3b77f2ceb5",
      "e0131763ce374ea0a26c386fac04cce0",
      "169e68de27ac46afb938cef01eb9f817",
      "be731f5eeca046a6a224d142503ed5b0",
      "154047df9cb146ff9d90673148f8919a",
      "2d1c0587c1db405c950c451af87e96cf",
      "4eaa7c650a7a48f8bfad4b17c73a1d13",
      "8ecdf55f3eff48519706335d9894d022",
      "1d40e005e3e04c279ee28cca0a992d7f",
      "d08e09e8ddc94552bc489513612a7962",
      "77781ad2c61548ad9f24630a62dfd57c",
      "9ec123c4694a4b649aa7b31388d71210",
      "78612192aa8c4c8db0c194fb6f00276e",
      "1aaefcf1f9814c3ca079ea6d4f730d07",
      "ad7b502eac78442b976f60a2a79ace81",
      "e3caf853ca2e48f4b4c192bdfa69ede8",
      "09a72f5fcc8843b8a909d938d5cff109",
      "269b6bc9f31e455c86587d22c25ecb49",
      "824d215289a24928a4161a279146d2e5",
      "f69bd2a835844082b4ee01b2e5ec2ae4",
      "8cec93586c9d4f1098aea0cad6fd90dc",
      "a1913dbadd8044d58484ebc5fc594002",
      "c5e2cdef2dc74d9f82d7eed17506dd4b"
     ]
    },
    "id": "NOKKj7PnQwQT",
    "outputId": "95a618b6-24e5-4adf-a619-6cc77a78371e"
   },
   "outputs": [],
   "source": [
    "# HIDE OUTPUT\n",
    "text2 = \"\"\"\n",
    "An apple is an edible fruit produced by an apple tree (Malus domestica). \n",
    "Apple trees are cultivated worldwide and are the most widely grown species \n",
    "in the genus Malus. The tree originated in Central Asia, where its wild \n",
    "ancestor, Malus sieversii, is still found today. Apples have been grown \n",
    "for thousands of years in Asia and Europe and were brought to North America \n",
    "by European colonists. Apples have religious and mythological significance \n",
    "in many cultures, including Norse, Greek, and European Christian tradition.\n",
    "\"\"\"\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rdx7Ubaf3ZZd"
   },
   "source": [
    "The following code summarizes the Wikipedia entry for an \"apple.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FuckG-KRaJt7",
    "outputId": "5cd060da-11ac-4609-dcdd-e643582a6740"
   },
   "outputs": [],
   "source": [
    "outputs = summarizer(text2, max_length=45,\n",
    "                     clean_up_tokenization_spaces=True)\n",
    "print(outputs[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaIVJol1b0Kq"
   },
   "source": [
    "## Text Generation\n",
    "\n",
    "Finally, text generation allows us to take an input text and request the pretrained neural network to continue that text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195,
     "referenced_widgets": [
      "cc9f2252779f4b20a22604d1f103db56",
      "135d73ed79c14731b3a25589630d33fd",
      "326374ed0a5147ac833e05b891f6925d",
      "f0b557940da744a6ac5c7d6ebb8c555b",
      "e4ea1836b265465495be7e45864240d4",
      "e77eecadd4a944c79ba69a48378318f9",
      "6ff57ff14e85444389946e23a870472d",
      "32351d8b2e4a4e27a5510efad07ee54c",
      "c0775fed1ff742b185073110fa690eeb",
      "b4d0ca5df984455aabdb5284241b08cd",
      "11160e800c374dddae6227885b0c3492",
      "de9d3f72587e412e9484af99aa208c1e",
      "1cabc5eaf399413998ab8fe121df099a",
      "02fec86ee3ec412385dd9fea03c83dd4",
      "d15fab0141c940668e541361af2bc26c",
      "e521840184fa468fa043096c84527747",
      "73e596c90f9542b786af4c840ca5c5f9",
      "e5a9552356124cdc904e95da5f1c578f",
      "7bffa607ddf84d4ea570c28832dfd143",
      "0716bdb0289d42a5a0e477dec6f67640",
      "8984eda37d1e48448a0966f57fa6e7e5",
      "04e3d8c589f54987bfcd94fb8497c288",
      "e09fc230df4340b180ffa956f058ffaa",
      "8e0301e7b44e400988e12a2ba23f6cbd",
      "d8d33c4752d44eaa975674c4c5f03c2d",
      "dc8191ec22614d50abe747ed43eaeedf",
      "9b23d9df9cfc44bdbca2f0450b606534",
      "950c15f739c6458188b7ae69f06081a7",
      "bb251f862adc4f88be72852df000648e",
      "520db5605dca4e71b788a6cbc75561a5",
      "62d3d628db66486c979c13870e3f0446",
      "9bca94f70ebf48698eec613b3b8c1ddc",
      "6294bb3b794f47efa82191832ab3f97d",
      "f6f0ac2c254146328a246155c518a74f",
      "1ad3d3acec7e40e1b1fb9407a8e12065",
      "1325c45befd44b3093a0ad0c53b33347",
      "3f565941338b4d77af76b7f624e6752f",
      "300236b97eb7488581f30dc7cce0b532",
      "459d767a54a243c19b41675c5ebb5ebb",
      "71e2af24406c4de7be975b996ac042f7",
      "8c7f9cd15341438d8dc0ae2b0a4c6b3e",
      "00c6032da2d341e9a976e1dcebbc7cc0",
      "2b40617547ec4131a395ca40f9fa5e2b",
      "57cfa69fb0a24e72a8d48d7af1d523be",
      "5d7b389fec7a4f7fbe4fbd5b237d1aee",
      "a089dd88cd1f448cb409957f8baabca9",
      "7722524cfafb4958954cd3a7919b764b",
      "d0990762047340adb0a607e8f13f4389",
      "6ba56818aa5347e6a6a98937558a5065",
      "9256e6fd7a0f4d82b22ce334db94390e",
      "bd177fe7397d4cb1bbc883f275feafa9",
      "138a85d0ed4f4b6f97ce4424635343b8",
      "b3738e27046245f08c8854a83265b805",
      "4d84624121e047fc9ffdec72f4eb4028",
      "3c1c65a974e24f39b0ba67c55bc04f52"
     ]
    },
    "id": "g4ZIA4bZRlhq",
    "outputId": "97331289-dd0a-4d75-d9a9-479e507a3c89"
   },
   "outputs": [],
   "source": [
    "# HIDE OUTPUT\n",
    "from urllib.request import urlopen\n",
    "\n",
    "generator = pipeline(\"text-generation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTmXcJpy3d24"
   },
   "source": [
    "Here an example is provided that generates additional text after Sonnet 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3E_zn8nCaPSc",
    "outputId": "f97b399c-7ca5-47d5-f1e3-0b8b95a333c6"
   },
   "outputs": [],
   "source": [
    "outputs = generator(text, max_length=400)\n",
    "print(outputs[0]['generated_text'])\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of t81_558_class_11_01_huggingface.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
