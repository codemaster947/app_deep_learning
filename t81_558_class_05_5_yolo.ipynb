{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKzF6dMaiLyP"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/app_deep_learning/blob/main/t81_558_class_05_5_yolo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDTXd8-Lmp8Q"
   },
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "**Module 6: Convolutional Neural Networks (CNN) for Computer Vision**\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ncNrAEpzmp8S"
   },
   "source": [
    "# Module 5 Material\n",
    "\n",
    "- Part 5.1: Image Processing in Python [[Video]](https://www.youtube.com/watch?v=Sob7VDb4xh8&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](t81_558_class_05_1_python_images.ipynb)\n",
    "- Part 5.2: Using Convolutional Neural Networks [[Video]](https://www.youtube.com/watch?v=jL0_lOpEwSk&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](t81_558_class_05_2_cnn.ipynb)\n",
    "- Part 5.3: Using Pretrained Neural Networks[[Video]](https://www.youtube.com/watch?v=W2T-dfiHYSo&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](t81_558_class_05_3_vision_transfer.ipynb)\n",
    "- Part 5.4: Looking at Generators and Image Augmentation [[Video]](https://www.youtube.com/watch?v=20JoEmQb810&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](t81_558_class_05_4_generators.ipynb)\n",
    "- **Part 5.5: Recognizing Multiple Images with YOLOv5** [[Video]](https://www.youtube.com/watch?v=7Uu1n9Tp0Mk&list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN) [[Notebook]](t81_558_class_05_5_yolo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0stsqSVoKD0"
   },
   "source": [
    "# Google CoLab Instructions\n",
    "\n",
    "The following code ensures that Google CoLab is running the correct version of TensorFlow.\n",
    "  Running the following code will map your GDrive to ```/content/drive```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fU9UhAxTmp8S",
    "outputId": "3704beed-4b41-4c87-81cb-ad74d9c32fd1"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSKZqD1Mmp-C"
   },
   "source": [
    "# Part 5.5: Recognizing Multiple Images with YOLO\n",
    "\n",
    "Programmers typically design convolutional neural networks to classify a single item centered in an image. However, as humans, we can recognize many items in our field of view in real-time. It is advantageous to recognize multiple items in a single image. One of the most advanced means of doing this is YOLO. You Only Look Once (YOLO) was introduced by Joseph Redmon, who supported YOLO up through V3. [[Cite:redmon2016you]](https://arxiv.org/abs/1506.02640) The fact that YOLO must only look once speaks to the efficiency of the algorithm. In this context, to \"look\" means to perform one scan over the image. It is also possible to run YOLO on live video streams.\n",
    "\n",
    "\n",
    "Joseph Redmon became less involved in YOLO after v3. The later versions, after YOLOv5 are supported by the startup company [Ultralytics](https://ultralytics.com/), who released the open-source library that we use in this class.[[Cite:zhu2021tph]](https://arxiv.org/abs/2108.11539)\n",
    "\n",
    "Researchers have trained YOLO on a variety of different computer image datasets. The version of YOLO weights used in this course is from the dataset Common Objects in Context (COCO). [[Cite: lin2014microsoft]](https://arxiv.org/abs/1405.0312) This dataset contains images labeled into 80 different classes. COCO is the source of the file coco.txt used in this module.\n",
    "\n",
    "## Using YOLO in Python\n",
    "\n",
    "To use YOLO in Python, we will use the open-source library provided by Ultralytics.\n",
    "\n",
    "* [YOLO Ultralytics GitHub](https://github.com/ultralytics/ultralytics)\n",
    "* [YOLO Documentation](https://docs.ultralytics.com/)\n",
    "\n",
    "The code provided in this notebook works equally well when run either locally or from Google CoLab. It is easier to run YOLO from CoLab, which is recommended for this course.\n",
    "\n",
    "We begin by obtaining an image to classify.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "WXEobzvGlFim",
    "outputId": "6b3159e6-2552-4c8e-806a-846f679660f9"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import shutil\n",
    "from IPython.display import Image\n",
    "!mkdir /content/images/\n",
    "\n",
    "URL = \"https://data.heatonresearch.com/images/wustl/photos/jeff_cook2.jpg\"\n",
    "LOCAL_IMG_FILE = \"/content/images/jeff_cook2.jpg\"\n",
    "\n",
    "with urllib.request.urlopen(URL) as response, \\\n",
    "  open(LOCAL_IMG_FILE, 'wb') as out_file:\n",
    "    shutil.copyfileobj(response, out_file)\n",
    "\n",
    "Image(filename=LOCAL_IMG_FILE, width=320)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ym5_juokofQl"
   },
   "source": [
    "## Installing YOLO\n",
    "\n",
    "YOLO is now available directly through PIP. The following commands install YOLO with PIP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VuTjby5MzEre",
    "outputId": "5c5a1f4c-e640-45b1-91ea-97ba6909bcad"
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PSttcoraUlb"
   },
   "source": [
    "Next, we will run YOLO from the command line and classify the previously downloaded kitchen picture.  You can run this classification on any image you choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dF6ONL3aCDFA",
    "outputId": "1870e8a6-ed66-4cf8-a58c-38063e95aa6f"
   },
   "outputs": [],
   "source": [
    "!yolo predict model=yolov8n-seg.pt source=$LOCAL_IMG_FILE imgsz=320"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpysCBL7C3jp"
   },
   "source": [
    "\tYou will see that there are several parameters that you can specify:\n",
    "  \n",
    "  * **imgsz** - Defines the image size for inference. Can be a single integer 640 for square resizing or a (height, width) tuple. Proper sizing can improve detection accuracy and processing speed. default=640\n",
    "  * **iou** - Intersection Over Union (IoU) threshold for Non-Maximum Suppression (NMS). Lower values result in fewer detections by eliminating overlapping boxes, useful for reducing duplicates. default=0.7\n",
    "  * **conf** = Sets the minimum confidence threshold for detections. Objects detected with confidence below this threshold will be disregarded. Adjusting this value can help reduce false positives. default=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybBPRdMvDfXt",
    "outputId": "76889202-7603-414a-b471-c5ad6f2fa8ee"
   },
   "outputs": [],
   "source": [
    "!ls ./runs/segment/predict/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "-jG5lNBcIvZD",
    "outputId": "42fb3920-dc00-4fc8-bd60-ecd4d8432a54"
   },
   "outputs": [],
   "source": [
    "# Display the images\n",
    "from IPython.display import Image\n",
    "\n",
    "file = './runs/segment/predict/jeff_cook2.jpg'\n",
    "Image(filename=file, width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYOvD3M7ofQl"
   },
   "source": [
    "## Running YOLO from Python\n",
    "\n",
    "In addition to the command line execution, we can also make use of YOLO right in Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YkuyRMlnS4NL",
    "outputId": "e2547ded-7e10-4296-ca16-f61f34ade455"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Use the model\n",
    "results = model(LOCAL_IMG_FILE, iou=0.7, conf=0.25)  # predict on an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSztA9ibx2iG"
   },
   "source": [
    "We will look at some of the information returned by the model. First we can get a list of all items it can recognize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ILv5aBmfxtC5",
    "outputId": "fcedddc9-7063-479e-d675-198ad9e59c37"
   },
   "outputs": [],
   "source": [
    "print(\"Classes supported\")\n",
    "print(results[0].names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtQWElY1x9-J"
   },
   "source": [
    "We can also see the classes detected here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v-VicGmrTqRv",
    "outputId": "66268eb8-6557-49ea-b627-148fb13b58fa"
   },
   "outputs": [],
   "source": [
    "results[0].boxes.cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pOlAXYL9yOlQ"
   },
   "source": [
    "It can be useful to group everything detected into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "2iOz_FXEgbWo",
    "outputId": "a387ed9f-a7af-40ff-ed64-c215386e4463"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def results_to_dataframe(results):\n",
    "    lookup = results[0].names\n",
    "    boxes = results[0].boxes\n",
    "\n",
    "    data = {\n",
    "        'class': [int(item) for item in boxes.cls],\n",
    "        'name': [lookup[int(item)] for item in boxes.cls],\n",
    "        'xmin': [int(box[0]) for box in boxes.xyxy],\n",
    "        'ymin': [int(box[1]) for box in boxes.xyxy],\n",
    "        'xmax': [int(box[2]) for box in boxes.xyxy],\n",
    "        'ymax': [int(box[3]) for box in boxes.xyxy],\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "df = results_to_dataframe(results)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
