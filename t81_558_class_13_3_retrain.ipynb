{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/app_deep_learning/blob/main/t81_558_class_13_3_retrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "**Module 13: Advanced/Other Topics**\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 13 Video Material\n",
    "\n",
    "* Part 13.1: Using Denoising AutoEncoders [[Video]](https://www.youtube.com/watch?v=BBrRD89sTk8&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_13_1_auto_encode.ipynb)\n",
    "* Part 13.2: Anomaly Detection [[Video]](https://www.youtube.com/watch?v=wubZ516TkI8&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_13_2_anomaly.ipynb)\n",
    "* **Part 13.3: Model Drift and Retraining** [[Video]](https://www.youtube.com/watch?v=F4395B1ySpg&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_13_3_retrain.ipynb)\n",
    "* Part 13.4: Tensor Processing Units (TPUs) [[Video]](https://www.youtube.com/watch?v=Cp3xOyxOZNo&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_13_4_tpu.ipynb)\n",
    "* Part 13.5: Future Directions in Artificial Intelligence [[Video]](https://www.youtube.com/watch?v=RjxvEZh73Yc&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_13_5_new_tech.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google CoLab Instructions\n",
    "\n",
    "The following code checks that Google CoLab is and sets up the correct hardware settings for PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False\n",
    "\n",
    "# Make use of a GPU or MPS (Apple) if one is available.  (see module 3.2)\n",
    "import torch\n",
    "has_mps = torch.backends.mps.is_built()\n",
    "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 13.3: Model Drift and Retraining\n",
    "\n",
    "Dataset drift is a problem frequently seen in real-world applications of machine learning. Academic problems that courses typically present in school assignments usually do not experience this problem. For a class assignment, your instructor provides a single data set representing all of the data you will ever see for a task. In the real world, you obtain initial data to train your model; then, you will acquire new data over time that you use your model to predict.\n",
    "\n",
    "Consider this example. You create a startup company that develops a mobile application that helps people find jobs. To train your machine learning model, you collect attributes about people and their careers. Once you have your data, you can prepare your neural network to suggest the best jobs for individuals. \n",
    "\n",
    "Once your application is released, you will hopefully obtain new data. This data will come from job seekers using your app. These people are your customers. You have x values (their attributes), but you do not have y-values (their jobs). Your customers have come to you to find out what their be jobs will be. You will provide the customer's attributes to the neural network, and then it will predict their jobs. Usually, companies develop neural networks on initial data and then use the neural network to perform predictions on new data obtained over time from their customers.\n",
    "\n",
    "Your job prediction model will become less relevant as the industry introduces new job types and the demographics of your customers change. However, companies must look if their model is still relevant as time passes. This change in your underlying data is called dataset drift. In this section, we will see ways that you can measure dataset drift.\n",
    "\n",
    "You can present your model with new data and see how its accuracy changes over time. However, to calculate efficiency, you must know the expected outputs from the model (y-values). You may not know the correct outcomes for new data that you are obtaining in real-time. Therefore, we will look at algorithms that examine the x-inputs and determine how much they have changed in distribution from the original x-inputs that we trained on. These changes are called dataset drift.\n",
    "\n",
    "Let's begin by creating generated data that illustrates drift. We present the following code to create a chart that shows such drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def true_function(x):\n",
    "    x2 = (x*8) - 1\n",
    "    return ((np.sin(x2)/x2)*0.6)+0.3\n",
    "    \n",
    "#\n",
    "x_train  = np.arange(0, 0.6, 0.01)\n",
    "x_test  = np.arange(0.6, 1.1, 0.01)\n",
    "x_true = np.concatenate( (x_train, x_test) )\n",
    "\n",
    "#\n",
    "y_true_train = true_function(x_train)\n",
    "y_true_test = true_function(x_test)\n",
    "y_true   = np.concatenate( (y_true_train, y_true_test) )\n",
    "\n",
    "#\n",
    "y_train = y_true_train + (np.random.rand(*x_train.shape)-0.5)*0.4\n",
    "y_test  = y_true_test + (np.random.rand(*x_test.shape)-0.5)*0.4\n",
    "\n",
    "#\n",
    "lr_x_train = x_train.reshape((x_train.shape[0],1))\n",
    "reg = LinearRegression().fit(lr_x_train, y_train)\n",
    "reg_pred = reg.predict(lr_x_train)\n",
    "print(reg.coef_[0])\n",
    "print(reg.intercept_)\n",
    "\n",
    "#\n",
    "plot.xlim([0,1.5])\n",
    "plot.ylim([0,1])\n",
    "l1 = plot.scatter(x_train, y_train, c=\"g\", label=\"Training Data\")\n",
    "l2 = plot.scatter(x_test, y_test, c=\"r\", label=\"Testing Data\")\n",
    "l3, = plot.plot(lr_x_train, reg_pred, color='black', linewidth=3, \n",
    "                label=\"Trained Model\")\n",
    "l4, = plot.plot(x_true, y_true, label = \"True Function\")\n",
    "plot.legend(handles=[l1, l2, l3, l4])\n",
    "\n",
    "#\n",
    "plot.title('Drift')\n",
    "plot.xlabel('Time')\n",
    "plot.ylabel('Sales')\n",
    "plot.grid(True, which='both')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"True function\" represents what the data does over time. Unfortunately, you only have the training portion of the data. Your model will do quite well on the data that you trained it with; however, it will be very inaccurate on the new test data presented. The prediction line for the model fits the training data well but does not fit the est data well.\n",
    "\n",
    "## Preprocessing the Sberbank Russian Housing Market Data\n",
    "\n",
    "The examples provided in this section use a Kaggle dataset named The Sberbank Russian Housing Market, which you can access from the following link.\n",
    "\n",
    "* [Sberbank Russian Housing Market](https://www.kaggle.com/c/sberbank-russian-housing-market/data)\n",
    "\n",
    "Because Kaggle provides datasets as training and test, we must load both of these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "PATH = \"/Users/jheaton/Downloads/sberbank-russian-housing-market\"\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(os.path.join(PATH,\"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(PATH,\"test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I provide a simple preprocess function that converts all numerics to z-scores and all categoricals to dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    for i in df.columns:\n",
    "        if df[i].dtype == 'object':\n",
    "            df[i] = df[i].fillna(df[i].mode().iloc[0])\n",
    "        elif (df[i].dtype == 'int' or df[i].dtype == 'float'):\n",
    "            df[i] = df[i].fillna(np.nanmedian(df[i]))\n",
    "\n",
    "    enc = LabelEncoder()\n",
    "    for i in df.columns:\n",
    "        if (df[i].dtype == 'object'):\n",
    "            df[i] = enc.fit_transform(df[i].astype('str'))\n",
    "            df[i] = df[i].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we run the training and test datasets through the preprocessing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(train_df)\n",
    "preprocess(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we remove thr target variable.  We are only looking for drift on the $x$ (input data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('price_doc',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KS-Statistic\n",
    "\n",
    "We will use the KS-Statistic to determine the difference in distribution between columns in the training and test sets. As a baseline, consider if we compare the same field to itself. In this case, we are comparing the **kitch_sq** in the training set. Because there is no difference in distribution between a field in itself, the p-value is 1.0, and the KS-Statistic statistic is 0. The P-Value is the probability of no difference between the two distributions. Typically some lower threshold is used for how low a P-Value is needed to reject the null hypothesis and assume there is a difference. The value of 0.05 is a standard threshold for p-values. Because the p-value is NOT below 0.05, we expect the two distributions to be the same. If the p-value were below the threshold, the **statistic** value becomes interesting. This value tells you how different the two distributions are. A value of 0.0, in this case, means no differences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "stats.ks_2samp(train_df['kitch_sq'], train_df['kitch_sq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do something more interesting.  We will compare the same field **kitch_sq** between the test and training sets.  In this case, the p-value is below 0.05, so the **statistic** value now contains the amount of difference detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ks_2samp(train_df['kitch_sq'], test_df['kitch_sq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we pull the KS-Stat for every field.  We also establish a boundary for the maximum p-value and how much of a difference is needed before we display the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train_df.columns:\n",
    "    ks = stats.ks_2samp(train_df[col], test_df[col])\n",
    "    if ks.pvalue < 0.05 and ks.statistic>0.1:\n",
    "        print(f'{col}: {ks}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Drift between Training and Testing Datasets by Training\n",
    "\n",
    "Sample the training and test into smaller sets to train.  We want 10K elements from each; however, the test set only has 7,662, so we only sample that amount from each side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = min(len(train_df),len(test_df))\n",
    "SAMPLE_SIZE = min(SAMPLE_SIZE,10000)\n",
    "print(SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the random samples from the training and test sets and add a flag called **source_training** to tell the two apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sample = train_df.sample(SAMPLE_SIZE, random_state=49)\n",
    "testing_sample = test_df.sample(SAMPLE_SIZE, random_state=48)\n",
    "\n",
    "# Is the data from the training set?\n",
    "training_sample['source_training'] = 1\n",
    "testing_sample['source_training'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we combine the data that we sampled from the training and test data sets and shuffle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build combined training set\n",
    "combined = testing_sample.append(training_sample)\n",
    "combined.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Now randomize\n",
    "combined = combined.reindex(np.random.permutation(combined.index))\n",
    "combined.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now generate $x$ and $y$ to train.  We attempt to predict the **source_training** value as $y$, which indicates if the data came from the training or test set.  If the model successfully uses the data to predict if it came from training or testing, then there is likely drift.  Ideally, the train and test data should be indistinguishable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ready to train\n",
    "y = combined['source_training'].values\n",
    "combined.drop('source_training',axis=1,inplace=True)\n",
    "x = combined.values\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will consider anything above a 0.75 AUC as having a good chance of drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 60, max_depth = 7,\n",
    "    min_samples_leaf = 5)\n",
    "lst = []\n",
    "\n",
    "for i in combined.columns:\n",
    "    score = cross_val_score(model,pd.DataFrame(combined[i]),y,cv=2,\n",
    "                            scoring='roc_auc')\n",
    "    if (np.mean(score) > 0.75):\n",
    "        lst.append(i)\n",
    "        print(i,np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
