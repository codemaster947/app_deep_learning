{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2KGmYpLe3FO"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/app_deep_learning/blob/main/t81_558_class_13_1_auto_encode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bU3u7-Tpe3FS"
   },
   "source": [
    "# T81-558: Applications of Deep Neural Networks\n",
    "**Module 13: Other Neural Network Techniques**\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xpl6ei7e3FT"
   },
   "source": [
    "# Module 13 Video Material\n",
    "\n",
    "* **Part 13.1: Using Denoising AutoEncoders** [[Video]](https://www.youtube.com/watch?v=BBrRD89sTk8&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_13_1_auto_encode.ipynb)\n",
    "* Part 13.2: Anomaly Detection [[Video]](https://www.youtube.com/watch?v=wubZ516TkI8&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_13_2_anomaly.ipynb)\n",
    "* Part 13.3: Model Drift and Retraining [[Video]](https://www.youtube.com/watch?v=F4395B1ySpg&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_13_3_retrain.ipynb)\n",
    "* Part 13.4: Tensor Processing Units (TPUs) [[Video]](https://www.youtube.com/watch?v=Cp3xOyxOZNo&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_13_4_tpu.ipynb)\n",
    "* Part 13.5: Future Directions in Artificial Intelligence [[Video]](https://www.youtube.com/watch?v=RjxvEZh73Yc&list=PLjy4p-07OYzuy_lHcRW8lPTLPTTOmUpmi) [[Notebook]](t81_558_class_13_5_new_tech.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google CoLab Instructions\n",
    "\n",
    "The following code checks that Google CoLab is and sets up the correct hardware settings for PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False\n",
    "\n",
    "# Make use of a GPU or MPS (Apple) if one is available.  (see module 3.2)\n",
    "import torch\n",
    "has_mps = torch.backends.mps.is_built()\n",
    "device = \"mps\" if has_mps else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E88gee0De3FU"
   },
   "source": [
    "# Part 13.1: Using Denoising AutoEncoders\n",
    "\n",
    "Function approximation is perhaps the original task of machine learning. Long before computers and even the notion of machine learning, scientists came up with equations to fit their observations of nature. Scientists find equations to demonstrate correlations between observations. For example, various equations relate mass, acceleration, and force.\n",
    "\n",
    "Looking at complex data and deriving an equation does take some technical expertise. The goal of function approximation is to remove intuition from the process and instead depend on an algorithmic method to automatically generate an equation that describes data. A regression neural network performs this task.  \n",
    "\n",
    "We begin by creating a function that we will use to chart a regression function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aeFmKdKQe3FU"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred, y, sort=True):\n",
    "    t = pd.DataFrame({'pred': pred, 'y': y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'], inplace=True)\n",
    "    plt.plot(t['y'].tolist(), label='expected')\n",
    "    plt.plot(t['pred'].tolist(), label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_LOS08_Le3FW"
   },
   "source": [
    "Next, we will attempt to approximate a slightly random variant of the trigonometric sine function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "id": "cZY0KhJbe3FW",
    "outputId": "43a764ec-1eda-4ee6-9fe5-070866196d87"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Data Preparation\n",
    "rng = np.random.RandomState(1)\n",
    "x = torch.tensor(np.sort(360 * rng.rand(100, 1), axis=0)).float()\n",
    "y = torch.tensor(np.sin(x * (np.pi / 180.0)).ravel()).view(-1, 1).float()\n",
    "\n",
    "\n",
    "# Model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(x.shape[1], 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 25),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(25, 1)\n",
    ")\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(25000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(x)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Predictions\n",
    "pred = model(x).detach().numpy()\n",
    "\n",
    "print(\"Actual\")\n",
    "print(y[:5].numpy())\n",
    "\n",
    "print(\"Pred\")\n",
    "print(pred[:5])\n",
    "\n",
    "# Use the same chart_regression function\n",
    "chart_regression(pred.flatten(), y.numpy(), sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdItzT4He3FY"
   },
   "source": [
    "As you can see, the neural network creates a reasonably close approximation of the random sine function.\n",
    "\n",
    "## Multi-Output Regression\n",
    "\n",
    "Unlike most models, neural networks can provide multiple regression outputs.  This feature allows a neural network to generate various outputs for the same input.  For example, you might train the MPG data set to predict MPG and horsepower.  One area in that multiple regression outputs can be helpful is autoencoders.  The following diagram shows a multi-regression neural network.  As you can see, there are multiple output neurons.  Usually, you will use multiple output neurons for classification.  Each output neuron will represent the probability of one of the classes.  However, in this case, it is a regression neural network.  Figure 13.MRG shows multi-output regression.\n",
    "\n",
    "**Figure 14.MRG: Multi-Output Regression**\n",
    "![Multi-Output Regression](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_13_multi_output.png \"Multi-Output Regression\")\n",
    "\n",
    "The following program uses a multi-output regression to predict both [sin](https://en.wikipedia.org/wiki/Trigonometric_functions#Sine.2C_cosine_and_tangent) and [cos](https://en.wikipedia.org/wiki/Trigonometric_functions#Sine.2C_cosine_and_tangent) from the same input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ffWDKg4oe3FZ",
    "outputId": "b909d0c1-dac1-4963-b2fb-eb13057de687"
   },
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "rng = np.random.RandomState(1)\n",
    "x = torch.tensor(np.sort(360 * rng.rand(100, 1), axis=0)).float()\n",
    "y = torch.tensor(np.array([np.pi * np.sin(x * (np.pi / 180.0)).ravel(), \n",
    "                           np.pi * np.cos(x * (np.pi / 180.0)).ravel()]).T).float()\n",
    "\n",
    "# Model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(x.shape[1], 100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 25),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(25, 2)  # Two output neurons\n",
    ")\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(25000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(x)\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Predictions\n",
    "pred = model(x).detach().numpy()\n",
    "\n",
    "# Evaluation\n",
    "score = np.sqrt(((pred - y.numpy()) ** 2).mean())\n",
    "print(\"Score (RMSE): {}\".format(score))\n",
    "\n",
    "print(\"Predicted:\")\n",
    "print(pred[20:25])\n",
    "\n",
    "print(\"Expected:\")\n",
    "print(y[20:25].numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vS9yEbMie3FZ"
   },
   "source": [
    "## Simple Autoencoder\n",
    "\n",
    "An autoencoder is a neural network with the same number of input neurons as it does outputs. The hidden layers of the neural network will have fewer neurons than the input/output neurons. Because there are fewer neurons, the auto-encoder must learn to encode the input to the fewer hidden neurons. The predictors (x) and output (y) are precisely the same in an autoencoder. Because of this, we consider autoencoders to be unsupervised. Figure 14.AUTO shows an autoencoder. \n",
    "\n",
    "**Figure 14.AUTO: Simple Auto Encoder**\n",
    "![Simple Auto Encoder](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/class_13_auto_encode.png \"Simple Auto Encoder\")\n",
    "\n",
    "The following program demonstrates a very simple autoencoder that learns to encode a sequence of numbers. Fewer hidden neurons will make it more difficult for the autoencoder to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NmRxYQwxe3Fa",
    "outputId": "b6e0f570-aa47-4779-d6f6-4ae43d7607a4"
   },
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "x = torch.tensor([range(10)]).float()\n",
    "\n",
    "# Model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(x.shape[1], 3),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(3, x.shape[1])  # Multiple output neurons\n",
    ")\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(x)\n",
    "    loss = criterion(outputs, x)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Predictions\n",
    "pred = model(x).detach().numpy()\n",
    "\n",
    "# Evaluation\n",
    "score = np.sqrt(((pred - x.numpy()) ** 2).mean())\n",
    "print(\"Score (RMSE): {}\".format(score))\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eu4j2n4Ce3Fa"
   },
   "source": [
    "## Autoencode (single image)\n",
    "\n",
    "We are now ready to build a simple image autoencoder.  The program below learns a capable encoding for the image.  You can see the distortions that occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "id": "uLLKupJZe3Fa",
    "outputId": "291abc87-0685-4f08-ab7c-a27bbf53213a"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "url = \"https://data.heatonresearch.com/images/jupyter/brookings.jpeg\"\n",
    "response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "img = Image.open(BytesIO(response.content))\n",
    "img = img.resize((128, 128), Image.LANCZOS)\n",
    "img_array = np.asarray(img).flatten() / 255.0\n",
    "img_tensor = torch.tensor(img_array, dtype=torch.float32)\n",
    "\n",
    "print(img_tensor.shape)\n",
    "print(img_tensor)\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(img_tensor.shape[0], 10),\n",
    "    #nn.ReLU(),\n",
    "    nn.Linear(10, img_tensor.shape[0])\n",
    ")\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "img_tensor = img_tensor.unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "for epoch in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(img_tensor)\n",
    "    loss = loss_function(output, img_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "rows, cols = img.size\n",
    "output = output.squeeze(0) * 255  # Scale back to original range\n",
    "img_array2 = output.detach().numpy().reshape(rows, cols, 3)\n",
    "img_array2 = np.clip(img_array2, 0, 255)  # Clip to ensure values are within 0-255\n",
    "img_array2 = img_array2.astype(np.uint8)  # Convert to uint8 for image representation\n",
    "img2 = Image.fromarray(img_array2, 'RGB')\n",
    "\n",
    "# Display the image\n",
    "img2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78V-F70pe3Fb"
   },
   "source": [
    "## Standardize Images\n",
    "\n",
    "When processing several images together, it is sometimes essential to standardize them.  The following code reads a sequence of images and causes them to all be of the same size and perfectly square.  If the input images are not square, cropping will occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "fke-vWK3e3Fb",
    "outputId": "c47e5c67-5c0f-4bb6-9f94-024aa4c02e37"
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageFile\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and process the images\n",
    "images = [\n",
    "    \"https://data.heatonresearch.com/images/jupyter/Brown_Hall.jpeg\",\n",
    "    \"https://data.heatonresearch.com/images/jupyter/brookings.jpeg\",\n",
    "    \"https://data.heatonresearch.com/images/jupyter/WUSTLKnight.jpeg\"\n",
    "]\n",
    "\n",
    "def make_square(img):\n",
    "    cols, rows = img.size\n",
    "    \n",
    "    if rows > cols:\n",
    "        pad = (rows - cols) / 2\n",
    "        img = img.crop((pad, 0, cols, cols))\n",
    "    else:\n",
    "        pad = (cols - rows) / 2\n",
    "        img = img.crop((0, pad, rows, rows))\n",
    "    \n",
    "    return img\n",
    "\n",
    "x = []\n",
    "\n",
    "for url in images:\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = False\n",
    "    response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    img = make_square(img)\n",
    "    img = img.resize((128, 128), Image.ANTIALIAS)\n",
    "    display(img)\n",
    "    img_array = np.array(img, dtype=np.float32) / 255.0  # Normalize to [0, 1]\n",
    "    img_array = img_array.flatten()\n",
    "    x.append(img_array)\n",
    "\n",
    "x = np.array(x)\n",
    "x = torch.tensor(x, dtype=torch.float32).to(device)  # Move data to the device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukvt5kW7e3Fc"
   },
   "source": [
    "## Image Autoencoder (multi-image)\n",
    "\n",
    "Autoencoders can learn the same encoding for multiple images.  The following code learns a single encoding for numerous images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network using Sequential\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(x.shape[1], 500),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(500, x.shape[1])\n",
    ").to(device)  # Move model to the device\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(7500):\n",
    "    # Forward pass\n",
    "    outputs = model(x)\n",
    "    loss = criterion(outputs, x)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    pred = pred.cpu().numpy()  # Move predictions back to CPU for processing\n",
    "\n",
    "# Display the generated images\n",
    "cols, rows = img.size\n",
    "for i in range(len(pred)):\n",
    "    img_array2 = pred[i].reshape(rows, cols, 3)\n",
    "    img_array2 = img_array2 * 255  # Convert back to [0, 255]\n",
    "    img_array2 = img_array2.astype(np.uint8)\n",
    "    img2 = Image.fromarray(img_array2, 'RGB')\n",
    "    display(img2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pd25Yhmve3Fc"
   },
   "source": [
    "## Adding Noise to an Image\n",
    "\n",
    "Autoencoders can handle noise.  First, it is essential to see how to add noise to an image.  There are many ways to add such noise.  The following code adds random black squares to the image to produce noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 820
    },
    "id": "hafFm_Lue3Fc",
    "outputId": "13cdd80c-07bc-42a5-fbfa-782401f42832"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image, ImageFile\n",
    "from matplotlib.pyplot import imshow\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Seed the random number generator, so images are consistant\n",
    "np.random.seed(42)  \n",
    "\n",
    "def add_noise(a):\n",
    "    a2 = a.copy()\n",
    "    rows = a2.shape[0]\n",
    "    cols = a2.shape[1]\n",
    "    s = int(min(rows,cols)/20) # size of spot is 1/20 of smallest dimension\n",
    "    \n",
    "    for i in range(100):\n",
    "        x = np.random.randint(cols-s)\n",
    "        y = np.random.randint(rows-s)\n",
    "        a2[y:(y+s),x:(x+s)] = 0\n",
    "        \n",
    "    return a2\n",
    "\n",
    "url = \"https://data.heatonresearch.com/images/jupyter/brookings.jpeg\"\n",
    "\n",
    "response = requests.get(url,headers={'User-Agent': 'Mozilla/5.0'})\n",
    "img = Image.open(BytesIO(response.content))\n",
    "img.load()\n",
    "img = img.resize((128, 128), Image.LANCZOS)\n",
    "\n",
    "img_array = np.asarray(img)\n",
    "rows = img_array.shape[0]\n",
    "cols = img_array.shape[1]\n",
    "\n",
    "print(\"Rows: {}, Cols: {}\".format(rows,cols))\n",
    "\n",
    "# Create new image\n",
    "img2_array = img_array.astype(np.uint8)\n",
    "print(img2_array.shape)\n",
    "img2_array = add_noise(img2_array)\n",
    "img2 = Image.fromarray(img2_array, 'RGB')\n",
    "img2        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLUjke4Oe3Fd"
   },
   "source": [
    "## Denoising Autoencoder\n",
    "\n",
    "You design a denoising autoencoder to remove noise from input signals. You train the network to convert noisy data ($x$) to the original input ($y$). The $y$ becomes each image/signal (just like a normal autoencoder); however, the $x$ becomes a version of $y$ with noise added.  Noise is artificially added to the images to produce $x$.  The following code creates ten noisy versions of each of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "2VHljXDJe3Fd",
    "outputId": "ab1e49e1-0bd1-4fa1-deab-d4ac7a40779c"
   },
   "outputs": [],
   "source": [
    "# HIDE OUTPUT 3\n",
    "%matplotlib inline\n",
    "from PIL import Image, ImageFile\n",
    "from matplotlib.pyplot import imshow\n",
    "import requests\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "images = [\n",
    "    \"https://data.heatonresearch.com/images/jupyter/Brown_Hall.jpeg\",\n",
    "    \"https://data.heatonresearch.com/images/jupyter/brookings.jpeg\",\n",
    "    \"https://data.heatonresearch.com/images/jupyter/WUSTLKnight.jpeg\"\n",
    "]\n",
    "\n",
    "def make_square(img):\n",
    "    cols,rows = img.size\n",
    "    \n",
    "    if rows>cols:\n",
    "        pad = (rows-cols)/2\n",
    "        img = img.crop((pad,0,cols,cols))\n",
    "    else:\n",
    "        pad = (cols-rows)/2\n",
    "        img = img.crop((0,pad,rows,rows))\n",
    "    \n",
    "    return img\n",
    "    \n",
    "x = []    \n",
    "y = []\n",
    "loaded_images = []\n",
    "    \n",
    "for url in images:\n",
    "    ImageFile.LOAD_TRUNCATED_IMAGES = False\n",
    "    response = requests.get(url,headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    img.load()\n",
    "    img = make_square(img)\n",
    "    img = img.resize((128,128), Image.LANCZOS)\n",
    "    \n",
    "    loaded_images.append(img)\n",
    "\n",
    "    for i in range(10):\n",
    "        img_array = np.asarray(img)\n",
    "        img_array_noise = add_noise(img_array)\n",
    "        \n",
    "        img_array = img_array.flatten()\n",
    "        img_array = img_array.astype(np.float32)\n",
    "        img_array = (img_array-128)/128\n",
    "        \n",
    "        img_array_noise = img_array_noise.flatten()\n",
    "        img_array_noise = img_array_noise.astype(np.float32)\n",
    "        img_array_noise = (img_array_noise-128)/128\n",
    "        \n",
    "        x.append(img_array_noise)\n",
    "        y.append(img_array)\n",
    "    \n",
    "x = np.array(x)\n",
    "x = torch.tensor(x, dtype=torch.float32).to(device)  \n",
    "\n",
    "y = np.array(y)\n",
    "y = torch.tensor(y, dtype=torch.float32).to(device)  \n",
    "\n",
    "print(\"Training size:\")\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T21Xjxbae3Fd"
   },
   "source": [
    "We now train the autoencoder neural network to transform the noisy images into clean images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ymVbl4Ade3Fd",
    "outputId": "a69e23a0-2acb-40ec-f80a-eea43f420972"
   },
   "outputs": [],
   "source": [
    "# Define the neural network using Sequential\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(x.shape[1], 500),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(500, x.shape[1])\n",
    ").to(device)  # Move model to the device\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(10000):\n",
    "    # Forward pass\n",
    "    outputs = model(x)\n",
    "    loss = criterion(outputs, x)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 945
    },
    "id": "hCPE0sgGe3Fe",
    "outputId": "aa8ecf41-b04c-4a14-c412-0eee05904061"
   },
   "outputs": [],
   "source": [
    "for z in range(3):\n",
    "    print(\"*** Trial {}\".format(z+1))\n",
    "    \n",
    "    # Choose random image\n",
    "    i = np.random.randint(len(loaded_images))\n",
    "    img = loaded_images[i]\n",
    "    img_array = np.asarray(img)\n",
    "    cols, rows = img.size\n",
    "\n",
    "    # Add noise\n",
    "    img_array_noise = add_noise(img_array)    \n",
    "\n",
    "    #Display noisy image\n",
    "    img2 = img_array_noise.astype(np.uint8)\n",
    "    img2 = Image.fromarray(img2, 'RGB')\n",
    "    print(\"With noise:\")\n",
    "    display(img2)\n",
    "\n",
    "    # Present noisy image to auto encoder\n",
    "    img_array_noise = img_array_noise.flatten()\n",
    "    img_array_noise = img_array_noise.astype(np.float32)\n",
    "    img_array_noise = (img_array_noise-128)/128\n",
    "    img_array_noise = np.array([img_array_noise])\n",
    "    x = torch.tensor(img_array_noise, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Test the model\n",
    "    with torch.no_grad():\n",
    "        pred = model(x)\n",
    "        pred = pred.cpu().numpy()  # Move predictions back to CPU for processing\n",
    "\n",
    "    # Display neural result\n",
    "    img_array2 = pred.reshape(rows,cols,3)\n",
    "    img_array2 = (img_array2*128)+128\n",
    "    img_array2 = img_array2.astype(np.uint8)\n",
    "    img2 = Image.fromarray(img_array2, 'RGB')\n",
    "    print(\"After auto encode noise removal\")\n",
    "    display(img2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of t81_558_class_14_02_auto_encode.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
